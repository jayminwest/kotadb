# Automation Expert Domain Expertise
# Last reviewed: 2026-02-04
# Domain: automation layer development with Claude Agent SDK

overview:
  description: |
    Automation expert domain provides specialized knowledge for kotadb's automation layer,
    which uses the Claude Agent SDK (@anthropic-ai/claude-code) to execute automated workflows.
    This domain covers SDK integration patterns, workflow orchestration, metrics tracking with
    SQLite, GitHub commenting via gh CLI, console output transparency, MCP toolset configuration,
    and cost tracking for AI operations.
    
  scope:
    primary_codebase:
      - automation/src/index.ts (CLI entry, env loading, metrics display)
      - automation/src/workflow.ts (SDK query() integration, message streaming)
      - automation/src/orchestrator.ts (multi-phase orchestration, SDK hooks)
      - automation/src/reporter.ts (ConsoleReporter for ANSI output, verbosity control)
      - automation/src/metrics.ts (SQLite metrics storage)
      - automation/src/github.ts (gh CLI commenting)
      - automation/src/worktree.ts (git worktree management for isolated execution)
      - automation/src/logger.ts (structured logging with JSON events)
      - automation/package.json (SDK dependency)
      - automation/tsconfig.json (TypeScript config)
      - automation/README.md (documentation)
      - app/src/cli/args.ts (CLI argument parsing with toolset tier support)
      - app/src/mcp/tools.ts (MCP tool definitions with tier metadata)
      - app/src/mcp/server.ts (MCP server with tool filtering)
      - automation/src/context.ts (workflow context storage for inter-phase handoffs)
      - automation/src/context.test.ts (context accumulation tests)
      - app/src/db/migrations/005_workflow_contexts.sql (workflow context schema)
    
    broader_scope:
      - Claude Agent SDK patterns (query(), message streaming, hooks, stderr callback)
      - MCP server configuration for kotadb access with toolset tiers
      - MCP tool organization (core, sync, memory, expertise tiers)
      - Tool filtering patterns for dynamic tool selection
      - Bun.spawn patterns for gh CLI integration
      - SQLite metrics storage (automation/.data/metrics.db)
      - ANSI escape code formatting for console output
      - Git worktree isolation for parallel workflow execution
      - SDK hook integration (PreToolUse, PostToolUse, Notification)
      - Workflow context accumulation patterns for multi-phase orchestration
      - Main KotaDB database integration (.kotadb/kota.db) for workflow context
      - Inter-phase data handoff patterns with structured context storage
      - Workflow ID generation patterns (adw-<issue>-<timestamp>)
      
    not_covered:
      - General Claude configuration (see claude-config expert)
      - GitHub issue/PR workflows (see github expert)
      - KotaDB API implementation (see api expert)
      
  rationale: |
    The automation layer represents a critical architectural component that orchestrates
    Claude Code workflows programmatically. This expertise enables reliable SDK integration,
    proper metrics tracking, effective workflow automation, and transparent console output
    while maintaining clear boundaries with related domains (github for GitHub operations,
    database for code intelligence storage).

core_implementation:
  database_location: automation/.data/metrics.db
  
  key_files:
    index_ts:
      path: automation/src/index.ts
      purpose: CLI entry point with env loading and metrics display
      responsibilities:
        - Parse CLI arguments (issue number, flags: --dry-run, --verbose, --metrics, --no-comment)
        - Load .env from project root for ANTHROPIC_API_KEY
        - Validate ANTHROPIC_API_KEY before workflow
        - Execute workflow via workflow.ts
        - Display metrics table or run workflow
        - Handle exit codes
        - Record metrics and post GitHub comments
        
    cli_args_ts:
      path: app/src/cli/args.ts
      purpose: CLI argument parsing with toolset tier validation
      responsibilities:
        - Define ToolsetTier type ("default" | "core" | "memory" | "full")
        - Parse --toolset flag with = and space syntax
        - Validate tier values with type guard isValidToolsetTier
        - Return parsed CliOptions with toolset field
        - Provide helpful error messages for invalid tiers
        
    mcp_tools_ts:
      path: app/src/mcp/tools.ts
      purpose: MCP tool definitions with tier-based filtering
      responsibilities:
        - Define ToolDefinition interface with tier field
        - Categorize tools into tiers (core, sync, memory, expertise)
        - Implement filterToolsByTier for dynamic tool selection
        - Map toolset tiers to tool tiers (core→core, default→core+sync, etc)
        - Export tool filtering utilities for MCP server
        
    mcp_server_ts:
      path: app/src/mcp/server.ts
      purpose: MCP server with toolset-aware tool registration
      responsibilities:
        - Accept toolset in McpServerContext
        - Filter tools by tier in ListToolsRequestSchema handler
        - Log filtered tool count for debugging
        - Thread toolset through server lifecycle
        
    orchestrator_ts:
      path: automation/src/orchestrator.ts
      purpose: Multi-phase workflow orchestration with SDK hook integration
      responsibilities:
        - Orchestrate 4-phase workflow (analysis, plan, build, improve)
        - Configure SDK options with hooks for action-level logging
        - Manage PreToolUse, PostToolUse, Notification hooks
        - Suppress SDK default stderr output via stderr callback
        - Handle dry-run mode with status tracking
        - Parse domain and requirements from analysis
        - Extract spec paths and file modifications
        
    reporter_ts:
      path: automation/src/reporter.ts
      purpose: Console output with ANSI formatting and verbosity control
      responsibilities:
        - Format workflow lifecycle events with ANSI colors
        - Provide verbosity-aware logging (verbose vs summary modes)
        - Summarize tool inputs and outputs for readable logging
        - Separate key actions (file write/edit) from verbose details
        - Track phase timing and metrics accumulation
        - Handle workflow completion with tokens and cost
        
    workflow_ts:
      path: automation/src/workflow.ts
      purpose: SDK query() integration and message streaming
      responsibilities:
        - Import query() from @anthropic-ai/claude-code
        - Configure SDK options (maxTurns, cwd, permissionMode, mcpServers, hooks)
        - Stream messages from async iterator
        - Extract session_id, usage, cost, errors
        - Record metrics via metrics.ts
        - Integrate ConsoleReporter for real-time progress
        
    metrics_ts:
      path: automation/src/metrics.ts
      purpose: SQLite metrics storage and retrieval
      responsibilities:
        - Auto-initialize workflow_metrics table
        - Record workflow start/completion
        - Store tokens, cost, duration, PR URL
        - Retrieve recent metrics for display
        - Handle DB errors gracefully
        
    github_ts:
      path: automation/src/github.ts
      purpose: GitHub commenting via gh CLI
      responsibilities:
        - Parse git remote for repo path
        - Format markdown table for metrics
        - Execute gh CLI via Bun.spawn
        - Handle auth failures gracefully
        - Support --no-comment flag


    worktree_ts:
      path: automation/src/worktree.ts
      purpose: Git worktree management for isolated workflow execution
      responsibilities:
        - Create isolated git worktrees for parallel execution
        - Format filesystem-safe timestamps for worktree naming
        - Manage worktree lifecycle with graceful fallback to projectRoot
        - Preserve worktrees on failure for debugging
        - Query worktree info via git worktree list --porcelain

    context_ts:
      path: automation/src/context.ts
      purpose: Workflow context accumulation for inter-phase handoffs
      responsibilities:
        - Store curated context data for workflow phases in main KotaDB database
        - Generate workflow IDs (adw-<issue>-<timestamp> format)
        - Retrieve phase-specific or full workflow context
        - Clear context after successful workflow completion
        - Validate phase consistency (data.phase must match parameter)
        - Use upsert semantics with ON CONFLICT for idempotency
        - Integrate with getGlobalDatabase() for main DB access
        - Support all ADW phases (analysis, plan, build, improve)

    migration_005:
      path: app/src/db/migrations/005_workflow_contexts.sql
      purpose: Schema for workflow context storage
      responsibilities:
        - Define workflow_contexts table with workflow_id, phase, context_data
        - Enforce phase CHECK constraint (analysis, plan, build, improve)
        - Provide UNIQUE constraint on (workflow_id, phase)
        - Index workflow_id for primary access pattern
        - Index created_at DESC for time-based queries
        - Store context_data as JSON TEXT blob
        - Record schema migration in schema_migrations table

key_operations:
  suppress_sdk_stderr:
    when: Providing custom console output without SDK default dots
    approach: |
      Configure SDK options with stderr callback that captures or ignores stderr.
      This suppresses default progress dots while allowing custom reporting via hooks.
    patterns:
      - SDK options include stderr callback function
      - Callback receives SDK progress updates
      - Return void to suppress, or implement custom handling
      - Use with hooks for structured output instead
    code_example: |
      const sdkOptions: AutomationSDKOptions = {
        maxTurns: 100,
        cwd: projectRoot,
        permissionMode: "bypassPermissions",
        // Suppress default stderr dots
        stderr: (data: string) => {
          if (verbose) {
            logger.logEvent("SDK_STDERR", { data });
          }
          // Suppress console output (SDK dots)
        },
        hooks: { /* ... */ }
      };
    pitfalls:
      - Not providing stderr callback shows default SDK progress
      - Verbose logging of SDK_STDERR fills logs unnecessarily
      - Mixing stderr callback with Notification hook creates duplicate output
      
  integrate_sdk_hooks:
    when: Adding action-level logging for tool execution
    approach: |
      Use SDK hooks (PreToolUse, PostToolUse, Notification) to intercept tool calls
      and SDK notifications. Implement HookCallback for each hook type. Configure
      via hooks option in SDK options.
    patterns:
      - PreToolUse: Log tool invocation with input summary
      - PostToolUse: Log tool completion with output summary
      - Notification: Log SDK notifications (errors, warnings, progress)
      - Wrap hooks in HookCallbackMatcher array with hooks property
      - Non-fatal hook failures allow workflow continuation
    code_example: |
      function createPreToolUseHook(reporter: ConsoleReporter): HookCallback {
        return async (input: HookInput) => {
          try {
            if (input.hook_event_name === "PreToolUse") {
              const summary = summarizeToolInput(input.tool_name, input.tool_input);
              reporter.logToolUse(input.tool_name, summary);
            }
          } catch {
            // Non-fatal: continue workflow on hook error
          }
          return {};
        };
      }
      
      const hooks: Partial<Record<string, HookCallbackMatcher[]>> = {
        PreToolUse: [{ hooks: [createPreToolUseHook(reporter)] }],
        PostToolUse: [{ hooks: [createPostToolUseHook(reporter)] }],
        Notification: [{ hooks: [createNotificationHook(reporter)] }]
      };
      
      const sdkOptions = {
        maxTurns: 100,
        hooks
      };
    pitfalls:
      - Hook exceptions should not terminate workflows (wrap in try-catch)
      - HookInput event_name must match hook type exactly
      - Tool input/output summarization must handle all tool types
      - Not returning {} from hook callback may break SDK
      
  implement_console_reporter:
    when: Creating user-facing real-time workflow progress output
    approach: |
      Build ConsoleReporter class with ANSI formatting constants, verbosity-aware
      logging methods, and phase timing. Use process.stdout.write for output.
      Separate console reporting from structured logging (logger.ts).
    patterns:
      - ANSI color constants (PHASE, ACTION, SUCCESS, ERROR, WARNING, VERBOSE)
      - Verbosity flag controls what gets logged (isVerbose method)
      - Key actions always logged (file writes/edits via isKeyAction)
      - Tool summaries only in verbose mode
      - Phase start/complete with timing
      - Workflow start/complete with full metrics summary
      - Process stream writes with fallback to stderr
    code_example: |
      export const ANSI = {
        RESET: "\x1b[0m",
        BOLD: "\x1b[1m",
        PHASE: "\x1b[1m\x1b[36m",    // cyan+bold
        ACTION: "\x1b[34m",           // blue
        SUCCESS: "\x1b[32m",          // green
        ERROR: "\x1b[1m\x1b[31m",    // red+bold
        WARNING: "\x1b[33m",          // yellow
        VERBOSE: "\x1b[2m"            // dim
      };
      
      class ConsoleReporter {
        logKeyAction(message: string): void {
          // Always shown
          this.write(`  ${ANSI.ACTION}->${ANSI.RESET} ${message}\n`);
        }
        
        logVerbose(message: string): void {
          // Only if verbose
          if (this.verbose) {
            this.write(`  ${ANSI.VERBOSE}${message}${ANSI.RESET}\n`);
          }
        }
        
        private write(text: string): void {
          try {
            process.stdout.write(text);
          } catch {
            // Fallback to stderr
            try {
              process.stderr.write(text);
            } catch {
              // Silent failure
            }
          }
        }
      }
    pitfalls:
      - Not providing fallback to stderr causes lost output
      - ANSI codes must be complete (bold+color combinations need both codes)
      - Forgetting RESET codes causes all subsequent output to be colored
      - Mixing console.* with process.std* breaks logging conventions
      
  summarize_tool_actions:
    when: Extracting readable summaries from tool input/output
    approach: |
      Create helper functions to extract meaningful summaries from tool input
      and output objects. Handle each tool type differently (Read vs Write vs Bash).
      Truncate long commands to avoid verbose output.
    patterns:
      - Separate summarizeToolInput and summarizeToolOutput functions
      - Tool-specific case branches (Read, Write, Edit, Bash, Grep, Glob, MCP tools)
      - Truncate long commands to ~60 chars
      - Extract file paths for Write/Edit
      - Extract patterns for Grep/Glob
      - Recognize Bash commands (test, tsc, lint) for standardized output
      - Return empty string if no meaningful summary
    code_example: |
      export function summarizeToolInput(toolName: string, toolInput: unknown): string {
        if (!toolInput || typeof toolInput !== "object") return "";
        const input = toolInput as Record<string, unknown>;
        
        switch (toolName) {
          case "Read":
            return `file: ${input.file_path}`;
          case "Bash": {
            const cmd = String(input.command || "");
            return `cmd: ${cmd.length > 60 ? cmd.substring(0, 60) + "..." : cmd}`;
          }
          case "Grep":
            return `pattern: "${input.pattern}"`;
          default:
            return "";
        }
      }
      
      export function isKeyAction(toolName: string): boolean {
        return ["Write", "Edit"].includes(toolName);
      }
    pitfalls:
      - Not handling all tool types returns empty summaries
      - Long command output makes logs unreadable
      - Not checking for undefined/null input causes crashes
      
  configure_verbose_flag:
    when: Adding --verbose/-v support for detailed output
    approach: |
      Parse --verbose or -v flag from CLI args. Pass to ConsoleReporter and
      orchestrator for depth control. Check verbose state in reporter methods
      to gate detailed output.
    patterns:
      - CLI flag parsing: args.includes("--verbose") || args.includes("-v")
      - Pass verbose boolean to ConsoleReporter constructor
      - Reporter.isVerbose() method for external hook access
      - Gate tool summaries and stack traces on verbose
      - Always show key actions and errors regardless of verbosity
    code_example: |
      // In index.ts
      const verbose = args.includes("--verbose") || args.includes("-v");
      
      // In orchestrator.ts
      const reporter = new ConsoleReporter({ verbose, issueNumber });
      
      // In hook callbacks
      if (reporter.isVerbose()) {
        reporter.logToolComplete(toolName, summary);
      }
    pitfalls:
      - Not exposing isVerbose() method breaks external access
      - Forgetting to gate some verbose output inconsistently
      - Verbose flag not passed through all orchestration layers

  integrate_sdk_query:
    when: Setting up Claude Agent SDK workflow execution
    approach: |
      Import query() from @anthropic-ai/claude-code and configure with appropriate
      options for automation context. Use async for...of loop to stream messages.
    patterns:
      - maxTurns 100 (allow complex multi-turn workflows)
      - permissionMode bypassPermissions (automation context, no interactive prompts)
      - cwd projectRoot (ensure correct working directory)
      - mcpServers Configure kotadb server with stdio transport
      - hooks for action-level logging
      - stderr callback to suppress default output
    code_example: |
      import { query, type SDKMessage } from "@anthropic-ai/claude-code";
      
      const messages: SDKMessage[] = [];
      for await (const message of query({
        prompt: `/do #${issueNumber}`,
        options: {
          maxTurns: 100,
          cwd: projectRoot,
          permissionMode: "bypassPermissions",
          mcpServers: {
            kotadb: {
              type: "stdio",
              command: "bunx",
              args: ["--bun", "kotadb"],
              env: { KOTADB_CWD: projectRoot }
            }
          },
          stderr: (data: string) => { /* suppress */ },
          hooks: { /* ... */ }
        }
      })) {
        messages.push(message);
        // Handle message types...
      }
    pitfalls:
      - Missing ANTHROPIC_API_KEY causes SDK error
      - Incorrect projectRoot path breaks kotadb MCP access
      - Not using bypassPermissions requires manual intervention
      - Low maxTurns value terminates complex workflows prematurely
      - Missing hooks means no action-level visibility
      
  stream_sdk_messages:
    when: Processing query() async iterator
    approach: |
      Use type guards to handle different SDKMessage types (system, assistant, result).
      Extract session_id from system init message, progress from assistant messages,
      and final usage/cost from result message.
    patterns:
      - Type guards for message discrimination
      - Progress logging via process.stderr.write or reporter
      - Session ID extraction from system init message
      - Final result extraction from result message
      - Error message extraction from error messages
    code_example: |
      function isSystemMessage(msg: SDKMessage): msg is SDKSystemMessage {
        return msg.type === "system" && "subtype" in msg && msg.subtype === "init";
      }
      
      function isResultMessage(msg: SDKMessage): msg is SDKResultMessage {
        return msg.type === "result";
      }
      
      for await (const message of query(...)) {
        if (isSystemMessage(message)) {
          sessionId = message.session_id;
        } else if (isResultMessage(message)) {
          usage = message.usage;
          success = message.success;
        }
      }
    pitfalls:
      - Not handling all message types leads to missing data
      - Using console.* breaks logging conventions
      - Not extracting session_id makes debugging difficult
      - Missing error state handling prevents failure tracking
      
  configure_mcp_server:
    when: Enabling kotadb MCP tools in SDK workflow
    approach: |
      Configure mcpServers object with stdio transport to enable kotadb code intelligence
      tools during SDK workflow execution. Pass KOTADB_CWD env var for correct indexing.
    patterns:
      - Server name kotadb matches SDK expectations
      - Type stdio for local server process
      - Command bunx with --bun flag for Bun runtime
      - Args for package execution
      - Env KOTADB_CWD for indexing context
    code_example: |
      mcpServers: {
        kotadb: {
          type: "stdio",
          command: "bunx",
          args: ["--bun", "kotadb", "--toolset", "memory"],
          env: { KOTADB_CWD: projectRoot }
        }
      }
    pitfalls:
      - Wrong transport type fails to connect
      - Missing KOTADB_CWD causes indexing in wrong directory
      - Incorrect package name breaks MCP server startup
      - Not using bunx --bun flag may use Node.js
      

  validate_anthropic_model_names:
    when: Configuring SDK queries with specific model versions
    approach: |
      Validate Anthropic model names follow the format claude-{variant}-{major}-{minor}-{date}.
      Use authoritative model list from Claude API documentation. Invalid model names cause
      HTTP 404 errors during query() execution.
    patterns:
      - Format: claude-{variant}-{major}-{minor}-{date}
      - Valid variants: opus, sonnet, haiku
      - Major/minor versions: integer values (e.g., 4.5, 3.5)
      - Date: 8-digit YYYYMMDD format (e.g., 20251001)
      - Examples: claude-opus-4-1-20250514, claude-haiku-4-5-20251001, claude-sonnet-4-20250514
    code_example: |
      // Valid model names (use these)
      const VALID_MODELS = {
        haiku: "claude-haiku-4-5-20251001",      // Haiku 4.5 (current)
        sonnet: "claude-sonnet-4-20250514",      // Sonnet 4 (current)
        opus: "claude-opus-4-1-20250514"         // Opus 4.1 (current)
      };
      
      // Invalid model names (these cause 404 errors)
      const INVALID_MODELS = {
        haiku_old: "claude-haiku-3-5-20241022",  // Non-existent version
        generic: "claude-haiku",                 // Missing version numbers
        bad_format: "claude-haiku-4-5"           // Missing date
      };
      
      // Validation function
      function isValidModelName(modelName: string): boolean {
        const pattern = /^claude-(opus|sonnet|haiku)-\d+\.\d+-\d{8}$/;
        return pattern.test(modelName);
      }
      
      // Usage in SDK options
      const sdkOptions = {
        model: "claude-haiku-4-5-20251001",  // Validated model name
        maxTurns: 20,
        // ...
      };
    pitfalls:
      - Typo in model name causes confusing 404 error instead of validation error
      - Using outdated model names stops working when Anthropic deprecates old versions
      - Copy-paste errors from documentation with different date formats
      - Mixing variant names (opus vs opuses, etc.)
      - Assuming hyphenated version numbers instead of dots

  record_workflow_metrics:
    when: Tracking workflow execution for analysis and cost monitoring
    approach: |
      Use SQLite database with auto-initialized schema to store workflow metrics.
      Record start time immediately, update on completion with tokens/cost/duration.
    patterns:
      - Auto-initialize schema on first DB access
      - Prepared statements for inserts
      - Index on issue_number and started_at for queries
      - Store session_id for debugging
      - Store PR URL extracted from SDK output
      - Record error messages for failed workflows
    pitfalls:
      - Not handling DB initialization errors prevents metrics storage
      - Missing indexes slow down queries
      - Not closing DB connection can corrupt metrics
      - Storing tokens as REAL loses precision
      
  post_github_comment:
    when: Reporting workflow results to GitHub issue
    approach: |
      Use gh CLI via Bun.spawn to post formatted comment with workflow results.
      Parse git remote for repo path, format duration/cost/tokens in markdown table.
    patterns:
      - gh CLI via Bun.spawn
      - Markdown table format for metrics
      - Success/failure emoji
      - Format duration as Xm Ys or Xs
      - Format cost with 4 decimal places
      - Parse git remote for repo
      - Non-fatal failure
    pitfalls:
      - gh auth not configured causes failure
      - Network failures are transient
      - Wrong repo format breaks comment posting
      - Not handling empty PR URL shows undefined
      
  configure_mcp_toolset:
    when: Selecting MCP tool tier for workflow requirements
    approach: |
      Configure mcpServers with --toolset flag to control which tools are available.
      Use tier-based filtering to balance capability with token overhead. Thread toolset
      from CLI args through server context to tool filtering logic.
    patterns:
      - Toolset tiers: core (6), default (8), memory (14), full (19 tools)
      - Tool tiers: core, sync, memory, expertise
      - Tier mapping: core→core, default→core+sync, memory→core+sync+memory, full→all
      - CLI parsing with --toolset flag (space and = syntax)
      - Type guard validation: isValidToolsetTier(value)
      - Context threading: CLI → McpServerContext → filterToolsByTier()
      - Hierarchical tool inclusion: each tier includes previous tiers
    code_example: |
      // CLI parsing (app/src/cli/args.ts)
      export type ToolsetTier = "default" | "core" | "memory" | "full";
      
      export function isValidToolsetTier(value: string): value is ToolsetTier {
        return ["default", "core", "memory", "full"].includes(value as ToolsetTier);
      }
      
      // MCP server configuration with toolset
      mcpServers: {
        kotadb: {
          type: "stdio",
          command: "bunx",
          args: ["--bun", "kotadb", "--toolset", "memory"],
          env: { KOTADB_CWD: projectRoot }
        }
      }
      
      // Tool filtering (app/src/mcp/tools.ts)
      export function filterToolsByTier(tier: ToolsetTier): ToolDefinition[] {
        const allTools = getToolDefinitions();
        switch (tier) {
          case "core":
            return allTools.filter((t) => t.tier === "core");
          case "default":
            return allTools.filter((t) => t.tier === "core" || t.tier === "sync");
          case "memory":
            return allTools.filter((t) => 
              t.tier === "core" || t.tier === "sync" || t.tier === "memory"
            );
          case "full":
            return allTools;
        }
      }
      
      // MCP server tool registration
      server.setRequestHandler(ListToolsRequestSchema, async () => {
        const tier = context.toolset || "default";
        const filteredTools = filterToolsByTier(tier);
        return { tools: filteredTools };
      });
    pitfalls:
      - Not validating toolset tier causes runtime errors
      - Forgetting to thread toolset through context breaks filtering
      - Tool tier metadata must be added to all ToolDefinitions
      - Hierarchical inclusion requirement: higher tiers must include lower tiers
      - Case-sensitive tier names ("core" not "CORE")
      
  implement_tool_tier_metadata:
    when: Adding new MCP tool or refactoring tool definitions
    approach: |
      Add tier field to ToolDefinition for every tool. Categorize by purpose:
      core for essential ops, sync for data export/import, memory for cross-session
      intelligence, expertise for domain validation tools.
    patterns:
      - ToolDefinition interface includes tier: ToolTier field
      - ToolTier type: "core" | "sync" | "memory" | "expertise"
      - Core tier: search_code, index_repository, list_recent_files, search_dependencies,
        analyze_change_impact, generate_task_context
      - Sync tier: kota_sync_export, kota_sync_import
      - Memory tier: search_decisions, record_decision, search_failures, record_failure,
        search_patterns, record_insight
      - Expertise tier: get_domain_key_files, validate_expertise, sync_expertise,
        get_recent_patterns, validate_implementation_spec
    code_example: |
      export const SEARCH_CODE_TOOL: ToolDefinition = {
        tier: "core",
        name: "search_code",
        description: "Search indexed code files...",
        inputSchema: { /* ... */ }
      };
      
      export const RECORD_DECISION_TOOL: ToolDefinition = {
        tier: "memory",
        name: "record_decision",
        description: "Record a new architectural decision...",
        inputSchema: { /* ... */ }
      };
    pitfalls:
      - Missing tier field breaks filterToolsByTier
      - Incorrect tier categorization confuses users
      - Not updating tests when adding tier metadata

  implement_context_accumulation:
    when: Enabling inter-phase data handoff for multi-phase workflows
    approach: |
      Store curated context at end of each phase in main KotaDB database (.kotadb/kota.db).
      Generate workflow ID at workflow start, pass through orchestration layers, store phase
      context with storeWorkflowContext(), clear on successful completion. Use main DB for
      future MCP tool integration (not metrics.db which is automation-specific).
    patterns:
      - Generate workflow ID generateWorkflowId(issueNumber) returns adw-<issue>-<timestamp>
      - Pass workflowId through orchestration (nullable for backward compatibility)
      - Store context storeWorkflowContext(workflowId, phase, data)
      - Retrieve context getWorkflowContext(workflowId, phase?) 
      - Clear on success clearWorkflowContext(workflowId) returns deleted count
      - Context data structure {phase, summary, keyFindings?, filesAnalyzed?, decisionsRecorded?, timestamp, ...custom}
      - Use main DB (getGlobalDatabase()) not metrics DB
      - Upsert semantics with ON CONFLICT for idempotency
      - CLI flag --accumulate-context to enable feature
    code_example: |
      // Generate workflow ID (workflow.ts)
      const workflowId = accumulateContext ? generateWorkflowId(issueNumber) : null;
      
      // Thread through orchestration (orchestrator.ts)
      export interface OrchestrationOptions {
        issueNumber: number;
        projectRoot: string;
        workflowId: string | null;  // Add this
        // ...
      }
      
      // Store phase context (in phase completion handler)
      if (workflowId) {
        const contextData: WorkflowContextData = {
          phase: 'analysis',
          summary: 'Analyzed requirements for feature X',
          keyFindings: ['Finding 1', 'Finding 2'],
          filesAnalyzed: ['src/foo.ts', 'src/bar.ts'],
          timestamp: new Date().toISOString()
        };
        storeWorkflowContext(workflowId, 'analysis', contextData);
      }
      
      // Retrieve context in next phase
      if (workflowId) {
        const analysisContext = getWorkflowContext(workflowId, 'analysis');
        // Use analysisContext to inform planning phase
      }
      
      // Clear context on success (orchestrator.ts)
      if (workflowId && improveStatus === "success") {
        const deletedCount = clearWorkflowContext(workflowId);
        logger.logEvent("CONTEXT_CLEANUP", { workflow_id: workflowId, deleted_count: deletedCount });
      }
    pitfalls:
      - Using metrics DB instead of main DB prevents MCP tool integration
      - Not passing workflowId through all orchestration layers breaks context flow
      - Forgetting to clear context on success causes accumulation
      - Phase mismatch validation data.phase must equal phase parameter
      - Context cleanup is non-fatal catch errors and log warnings
      - NULL workflowId requires safe navigation throughout codebase
      - Storing unstructured data makes retrieval unpredictable


decision_trees:
  console_output_strategy:
    question: How should I output console feedback for this event?
    branches:
      - condition: File creation/modification
        action: Call reporter.logKeyAction() - always shown
        rationale: Critical user feedback regardless of verbosity
        
      - condition: Tool execution details (input/output)
        action: Call reporter.logToolUse()/logToolComplete() - verbose only
        rationale: Too much detail for normal output
        
      - condition: Phase start/completion
        action: Call reporter.startPhase()/completePhase() - always shown
        rationale: Key workflow milestones
        
      - condition: Debugging information (timing, stack traces)
        action: Call reporter.logVerbose() - verbose only
        rationale: Only useful for troubleshooting
        
      - condition: Errors and warnings
        action: Call reporter.logError()/logWarning() - always shown
        rationale: Critical for workflow success
        
  sdk_output_suppression:
    question: How do I control SDK default output (dots, progress)?
    branches:
      - condition: Want no SDK output at all
        action: Provide stderr callback that ignores data
        rationale: Custom reporting via hooks replaces SDK output
        
      - condition: Want SDK output for debugging
        action: Log stderr via logger.logEvent("SDK_STDERR", ...)
        rationale: Preserved in logs but not on console
        
      - condition: Want progress in verbose mode only
        action: Check verbose flag in stderr callback
        rationale: Selective output based on user preference

  sdk_option_selection:
    question: Which SDK options should I use for automation workflows?
    branches:
      - condition: Always in automation context
        action: Use permissionMode bypassPermissions
        rationale: No human in loop for permission prompts
        
      - condition: Complex multi-step workflows
        action: Set maxTurns to 100 or higher
        rationale: Prevents premature termination
        
      - condition: Need kotadb code intelligence
        action: Configure mcpServers with kotadb stdio transport
        rationale: Enables code search and dependency analysis
        
      - condition: Multiple repositories or paths
        action: Set cwd to projectRoot
        rationale: Ensures correct working directory
        
      - condition: Need action-level visibility
        action: Configure PreToolUse, PostToolUse, Notification hooks
        rationale: Transparent action logging without SDK verbosity
        
  message_type_handling:
    question: How should I handle this SDK message type?
    branches:
      - condition: Message type is system with subtype init
        action: Extract session_id for debugging
        
      - condition: Message type is assistant
        action: Log progress to stderr, accumulate for final PR extraction
        
      - condition: Message type is result
        action: Extract usage, cost, success status
        
      - condition: Message type is error
        action: Record error message, mark workflow failed
        
  metrics_vs_logging:
    question: Should I store this data in metrics DB or just log it?
    branches:
      - condition: Workflow outcome data
        action: Store in metrics.db
        rationale: Persistent tracking for analysis
        
      - condition: Progress updates
        action: Log to console via reporter
        rationale: Real-time feedback
        
      - condition: Structured events
        action: Log to logger (JSON events)
        rationale: Queryable event history
        
      - condition: Errors
        action: Log to console AND store in metrics if workflow-level
        rationale: Both immediate feedback and historical tracking
  mcp_toolset_selection:
    question: Which toolset tier should I use for this workflow?
    branches:
      - condition: Minimal token overhead, basic code intelligence only
        action: Use --toolset core (6 tools)
        rationale: Smallest footprint for simple search/indexing tasks
        
      - condition: Standard workflows with occasional data sync
        action: Use --toolset default (8 tools) or omit flag
        rationale: Balanced capability, includes sync tools
        
      - condition: Need cross-session memory (decisions, failures, patterns)
        action: Use --toolset memory (14 tools)
        rationale: Enables persistent intelligence layer
        
      - condition: Advanced workflows requiring expertise validation
        action: Use --toolset full (19 tools)
        rationale: All capabilities including domain validation

  context_storage_database:
    question: Which database should I use for workflow context storage?
    branches:
      - condition: Context for inter-phase workflow handoffs
        action: Use main KotaDB database (.kotadb/kota.db) via getGlobalDatabase()
        rationale: Enables future MCP tool access to workflow context, integrates with code intelligence
        
      - condition: Automation execution metrics (tokens, cost, duration)
        action: Use automation metrics DB (automation/.data/metrics.db)
        rationale: Automation-specific operational data, not code intelligence
        
      - condition: Code intelligence data (symbols, references, dependencies)
        action: Use main KotaDB database (.kotadb/kota.db)
        rationale: Core code intelligence storage

  context_accumulation_enablement:
    question: When should context accumulation be enabled?
    branches:
      - condition: Multi-phase workflows requiring inter-phase handoffs
        action: Enable with --accumulate-context flag
        rationale: Future feature for context-aware phase orchestration
        
      - condition: Standard single-shot workflows
        action: Omit --accumulate-context flag (default)
        rationale: Avoid overhead when context not needed
        
      - condition: Debugging context accumulation
        action: Enable flag and inspect workflow_contexts table
        rationale: Verify context storage and cleanup behavior


patterns:
  console_reporter_pattern:
    structure: Class with ANSI constants, verbosity-aware methods, phase tracking
    usage: Real-time user feedback with transparent action logging
    trade_offs: Verbosity control vs completeness of output
      
  sdk_hook_pattern:
    structure: HookCallback functions with event_name discrimination
    usage: Intercept tool execution and SDK notifications
    trade_offs: Hook overhead vs detailed visibility
      
  tool_summary_pattern:
    structure: Tool-specific summarization functions (input/output)
    usage: Readable action logging without overwhelming output
    trade_offs: Simplification vs full details (use verbose for details)
      
  stderr_callback_pattern:
    structure: SDK options.stderr callback that accepts string
    usage: Suppress or redirect default SDK progress output
    trade_offs: Custom output vs SDK default formatting
      
  sdk_query_pattern:
    structure: Async for...of loop over query() iterator
    usage: Stream messages, accumulate results, handle errors
    trade_offs: Streaming progress vs batched results
      
  type_guard_pattern:
    structure: Type predicates for SDKMessage union types
    usage: isSystemMessage, isAssistantMessage, isResultMessage
    trade_offs: Type safety vs runtime overhead
      
  metrics_schema_pattern:
    structure: SQLite auto-initialization, prepared statements
    usage: workflow_metrics table with indexes
    trade_offs: Storage overhead vs queryability
      
  github_comment_pattern:
    structure: gh CLI via Bun.spawn, markdown table
    usage: Post workflow results with emoji, metrics table
    trade_offs: gh CLI dependency vs API complexity
      
  cli_argument_pattern:
    structure: Simple flag detection, positional args
    usage: --dry-run, --metrics, --no-comment, --verbose/-v
    trade_offs: Simple parsing vs rich CLI library

  workflow_id_generation_pattern:
    structure: adw-<issueNumber>-<timestamp> format with filesystem-safe timestamp
    usage: Unique identifier for workflow runs enabling context accumulation
    trade_offs: Timestamp precision vs readability (ISO format with punctuation removed)

  context_upsert_pattern:
    structure: INSERT ON CONFLICT UPDATE with upsert semantics
    usage: Idempotent context storage allowing phase re-execution
    trade_offs: Overwrite old data vs error on duplicate (chose overwrite for idempotency)

best_practices:
  console_output:
    - Use ConsoleReporter for all user-facing output
    - Separate ANSI formatting constants for maintainability
    - Always provide fallback to stderr if stdout fails
    - Gate verbose output in external code (use isVerbose method)
    - Never use console.* (use process.std* only)
    - Format numbers consistently (cost with 4 decimals, duration in seconds)
    
  sdk_hook_integration:
    - Wrap hooks in try-catch to prevent workflow interruption
    - Ensure HookCallback returns empty object {}
    - Use HookInput event_name to discriminate hook types
    - Implement separate functions for each hook type for clarity
    - Consider non-fatal hook failures as expected
    - Don't duplicate output between hooks (stderr vs hooks)
    
  console_output_suppression:
    - Always provide stderr callback to control SDK output
    - Use callback to filter (suppress) or redirect output
    - Consider verbosity flag when logging SDK_STDERR events
    - Avoid logging SDK output to console (use logger instead)
    
  tool_summarization:
    - Create separate functions for input and output summaries
    - Handle each tool type in switch statement
    - Truncate long commands to avoid verbose output
    - Return empty string if no meaningful summary exists
    - Keep summaries under 80 chars for readability
    
  verbose_flag_usage:
    - Parse from CLI args (--verbose or -v)
    - Pass to ConsoleReporter constructor
    - Access via reporter.isVerbose() in external code
    - Gate stack traces and detailed logs on verbosity
    - Always show errors and key actions regardless
    
  mcp_toolset:    
  mcp_toolset:
    - Use --toolset flag to control tool availability
    - Default tier (8 tools) for standard workflows
    - Core tier (6 tools) for minimal token footprint
    - Memory tier (14 tools) when cross-session intelligence needed
    - Full tier (19 tools) for advanced validation workflows
    - Add tier metadata to all new ToolDefinitions
    - Validate toolset values with type guards
    - Thread toolset through McpServerContext
    - Test hierarchical inclusion (higher tiers include lower)
  
  sdk_integration:
    - Always validate ANTHROPIC_API_KEY before query()
    - Use type guards for message handling
    - Configure mcpServers for kotadb access
    - Set permissionMode bypassPermissions for automation
    - Configure hooks for action-level logging
    - Provide stderr callback to suppress default output
    
  metrics_storage:
    - Auto-initialize schema on first use
    - Use prepared statements for inserts
    - Index on issue_number and started_at
    - Store session_id for debugging
    
  error_handling:
    - Non-fatal GitHub comment failures
    - Graceful env loading failures
    - Record failed workflow metrics
    - Always close metrics DB on exit
    - Catch hook exceptions to prevent workflow termination
    
  logging:
    - Use process.stdout.write for output
    - Use process.stderr.write for progress/errors
    - Format duration properly
    - Format cost with 4 decimals
    - Separate ConsoleReporter from structured logger

  workflow_context:
    - Store context in main KotaDB database for MCP tool access
    - Generate workflow ID at workflow start, pass through all layers
    - Use nullable workflowId for backward compatibility
    - Validate phase consistency (data.phase === phase parameter)
    - Clear context only on successful workflow completion
    - Make context cleanup non-fatal (log warning, continue)
    - Structure context data with phase, summary, timestamp, and optional fields
    - Use upsert semantics for idempotent context storage

known_issues:
  - issue: Invalid Anthropic model name causes HTTP 404 errors
    impact: SDK query() fails with confusing 404 error during curation/recording
    resolution: Use correct model format (claude-{variant}-{major}-{minor}-{date}), e.g., claude-haiku-4-5-20251001
    status: Fixed in #163, validate model names before using
    
  - issue: SDK query() timeout on long workflows
    impact: Workflow fails mid-execution
    resolution: Increase maxTurns, optimize workflow
    status: Operational guidance
    
  - issue: GitHub comment auth failures
    impact: Metrics recorded but no issue comment
    resolution: Non-fatal, log warning and continue
    status: Handled gracefully
    
  - issue: ANSI escape codes in non-TTY environments
    impact: Colored output appears as escape codes in logs
    resolution: Consider environment detection or flag
    status: Known limitation

potential_enhancements:
  - TTY detection for conditional ANSI code usage
  - Workflow pause/resume capability
  - Cost budget enforcement
  - Retry logic for transient failures
  - Workflow visualization UI
  - Metrics aggregation and reporting
  - Real-time progress bar using ANSI codes
  - Tool execution timeline visualization

stability:
  insight_rate_trend: converging
  contradiction_count: 0
  last_reviewed: 2026-02-04
  notes: |
    Issue #144 adds workflow context accumulation for inter-phase handoffs in ADW workflows.
    Key architectural decision: Store context in main KotaDB database (.kotadb/kota.db) 
    rather than automation metrics DB to enable future MCP tool integration. Context data
    uses flexible JSON structure with required fields (phase, summary, timestamp) and 
    optional fields (keyFindings, filesAnalyzed, decisionsRecorded). Workflow ID generation
    follows adw-<issue>-<timestamp> pattern. Upsert semantics allow idempotent phase
    re-execution. Context cleanup is non-fatal and occurs only on workflow success.
    
    Implementation establishes foundation for future context-aware orchestration where
    downstream phases can access curated data from upstream phases. CLI flag 
    --accumulate-context enables feature for backward compatibility.
    
    
    Model Naming Fix (#163): Corrected haiku model name from invalid claude-haiku-3-5-20241022
    to valid claude-haiku-4-5-20251001. Anthropic model naming follows strict format:
    claude-{variant}-{major}-{minor}-{date}. Invalid names cause API 404 errors. Added validation
    guidance to prevent future occurrences. This bug was blocking context curation in #148.
    
    Prior: Issue #95 (toolset tiers), #65 (console transparency), #64 (worktree isolation).
    Domain converging with comprehensive automation patterns established.

  curate_context_between_phases:
    when: Need to inject relevant memory context between workflow phases
    approach: |
      Use lightweight haiku curator to query KotaDB memory tools (failures, patterns, 
      decisions) and produce ~500 token curated summary for next phase. Curator runs
      as separate SDK query() call between phases.
    patterns:
      - Separate haiku SDK call with memory toolset
      - Query search tool with scope=["failures", "patterns", "decisions"]
      - Extract structured output (summary + items)
      - Store via storeWorkflowContext() for next phase access
      - Non-fatal failures (log warning, continue workflow)
      - Token budget: ~500 tokens per curation
      - Timing: <2s per curator call (haiku is fast)
    code_example: |
      const curatedContext = await curateContext({
        workflowId,
        phase: 'post-analysis',
        domain: 'database',
        currentPhaseOutput: analysisResult,
        projectRoot,
        logger,
        reporter
      });
      
      // Context automatically stored and available to next phase
    pitfalls:
      - Not handling curator failures gracefully breaks workflow
      - Overly verbose summaries exceed token budget
      - Missing workflowId prevents context storage
      - Curator must use memory toolset for search access
  
  auto_record_workflow_outcomes:
    when: Workflow completes (success or failure)
    approach: |
      Automatically record workflow outcomes to KotaDB memory tools using haiku.
      Success -> record_decision, Failure -> record_failure. Runs once per workflow
      (not per-phase) after improve phase completes.
    patterns:
      - Separate haiku SDK call with memory toolset
      - Retrieve all workflow contexts for summary
      - Success: record_decision with pattern scope
      - Failure: record_failure with error details
      - Include related_files array
      - Non-fatal failures (log warning, continue)
      - Dry-run mode skips recording
    code_example: |
      // Success recording
      await autoRecordSuccess({
        workflowId,
        issueNumber: 123,
        domain: 'automation',
        filesModified: ['src/orchestrator.ts', 'src/curator.ts'],
        projectRoot,
        logger,
        reporter
      });
      
      // Failure recording
      await autoRecordFailure({
        workflowId,
        issueNumber: 123,
        domain: 'automation',
        error: 'Build phase failed: type error in curator.ts',
        projectRoot,
        logger,
        reporter
      });
    pitfalls:
      - Recording before workflow truly completes
      - Missing context retrieval loses valuable data
      - Recording in dry-run mode pollutes memory
      - Exceptions in recording shouldn't fail workflow

  context_curation_timing:
    question: When should context curation run?
    branches:
      - condition: After analysis phase
        action: Curate context for plan phase
        rationale: Plan needs failure/pattern/decision context
        
      - condition: After plan phase
        action: Curate context for build phase
        rationale: Build needs refined context from planning
        
      - condition: After build phase
        action: Curate context for improve phase
        rationale: Improve needs build outcomes for learning
        
      - condition: After improve phase
        action: Auto-record outcome (no curation)
        rationale: Workflow complete, record for future runs
        
      - condition: Curator fails
        action: Log warning, continue workflow
        rationale: Curation is enhancement, not blocker

  memory_tool_usage:
    question: Which memory tool should I use?
    branches:
      - condition: Need to find past failures for domain
        action: search({scope: ["failures"], query: domain})
        rationale: Avoid repeating mistakes
        
      - condition: Need established patterns for domain
        action: search({scope: ["patterns"], query: domain})
        rationale: Follow conventions
        
      - condition: Need architectural decisions
        action: search({scope: ["decisions"], query: domain})
        rationale: Understand past choices
        
      - condition: Workflow succeeded
        action: record_decision with pattern scope
        rationale: Share success for future workflows
        
      - condition: Workflow failed
        action: record_failure with error details
        rationale: Learn from failures
        
      - condition: Discovered insight during workflow
        action: record_insight with discovery/workaround type
        rationale: Share discoveries

  haiku_curator_pattern:
    structure: Separate SDK query() call with haiku model between phases
    usage: Query memory tools, synthesize curated summary, store context
    trade_offs: Extra SDK call overhead vs intelligent context injection
    
  auto_recording_pattern:
    structure: Post-workflow haiku call to record outcome
    usage: Success -> decision, Failure -> failure, learning flywheel
    trade_offs: Extra SDK call vs systematic learning accumulation

  context_curation:
    - Run curator between phases for context continuity
    - Use haiku model for speed and cost efficiency
    - Target ~500 token summaries (concise, actionable)
    - Query all three memory scopes (failures, patterns, decisions)
    - Store curated context via storeWorkflowContext()
    - Make curation failures non-fatal (log, continue)
    - Monitor curator timing (<2s per call)
    - Use memory toolset for curator SDK calls
  
  auto_recording:
    - Record once per workflow (not per phase)
    - Run after improve phase completes
    - Include all workflow contexts in recording
    - Success: record_decision with pattern scope
    - Failure: record_failure with full error context
    - Include related_files array for traceability
    - Skip recording in dry-run mode
    - Make recording failures non-fatal

  notes: |
    Issue #148 implements deep KotaDB integration with haiku-powered context curation
    and automated workflow outcome recording. Key architectural decisions:
    
    1. Curator Strategy: Lightweight haiku model (claude-haiku-4-5-20251001) runs between
       phases to query memory tools and produce ~500 token curated summaries. Separate
       SDK calls maintain clear separation from main workflow execution.
    
    2. Auto-Recording: Successful workflows recorded as decisions (pattern scope), failed
       workflows recorded as failures with full error context. Enables learning flywheel
       where every ADW run benefits from past experience.
    
    3. Memory Toolset: Curator and auto-recording use --toolset memory to access unified
       search tool with scope parameter (failures/patterns/decisions) and recording tools.
    
    4. Non-Fatal Failures: All curation and recording failures are non-fatal. Workflow
       continues with warning logs. This prevents memory system issues from blocking
       primary automation functionality.
    
    5. Agent Registry: All 40+ agents now have access to memory tools (search, record_decision,
       record_failure, record_insight) enabling systematic knowledge accumulation across
       all expert domains.
    
    Implementation establishes foundation for intelligent multi-phase workflows where each
    phase benefits from curated context about past failures, established patterns, and
    architectural decisions. Combined with #144 context accumulation infrastructure,
    creates robust inter-phase handoff mechanism.
    
    
    Model Naming Fix (#163): Corrected haiku model name from invalid claude-haiku-3-5-20241022
    to valid claude-haiku-4-5-20251001. Anthropic model naming follows strict format:
    claude-{variant}-{major}-{minor}-{date}. Invalid names cause API 404 errors. Added validation
    guidance to prevent future occurrences. This bug was blocking context curation in #148.
    
    Prior: #144 (context accumulation), #143 (unified search), #95 (toolset tiers).
    Domain converging with comprehensive memory integration patterns established.

    curator_ts:
      path: automation/src/curator.ts
      purpose: Haiku-powered context curator for inter-phase handoffs
      responsibilities:
        - Query KotaDB memory tools (search with scope parameter)
        - Produce ~500 token curated summaries
        - Extract structured output (summary, failures, patterns, decisions)
        - Store curated context via storeWorkflowContext()
        - Run between workflow phases (post-analysis, post-plan, post-build)
        - Use haiku model (claude-haiku-4-5-20251001) for speed and cost
        - Configure memory toolset for search access
        
    auto_record_ts:
      path: automation/src/auto-record.ts
      purpose: Automated workflow outcome recording
      responsibilities:
        - Record successful workflows as decisions (record_decision tool)
        - Record failed workflows as failures (record_failure tool)
        - Retrieve all workflow contexts for comprehensive summary
        - Use haiku model for recording calls
        - Include related_files array for traceability
        - Skip recording in dry-run mode
        - Non-fatal failures (log warning, continue)
