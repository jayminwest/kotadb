# KotaDB Indexer Expertise
# Target: 400-600 lines | Domain: Operational knowledge for code indexing subsystem
# Adapted for KotaDB local-only architecture with SQLite storage

overview:
  description: |
    Code indexing subsystem for KotaDB—AST parsing with @typescript-eslint/parser, visitor pattern
    for symbol and reference extraction, import path resolution, dependency graph construction,
    and SQLite storage with transactional writes. This expertise enables correct implementation
    of indexing features within KotaDB's local-only architecture.
  scope: |
    Covers AST parsing (parseFile, isSupportedForAST), symbol extraction (extractSymbols with
    visitor pattern), reference extraction (imports, calls, property access, type references),
    import resolution (resolveImport, handleIndexFiles), dependency graph construction
    (buildFileDependencies, buildSymbolDependencies), SQLite storage (storeIndexedData),
    and FTS5 full-text search (searchFilesLocal with escapeFts5Term).

    KOTADB ADAPTATIONS:
    - Uses @typescript-eslint/parser (NOT Babel or TypeScript compiler API)
    - Graceful error handling (return null on parse errors, log warnings)
    - Local SQLite storage with single-transaction atomicity
    - FTS5 full-text search with proper escaping for special characters
    - Path aliases (@api/*, @indexer/*, @shared/*, etc.)
    - Logging via createLogger (never console.*)
    - TSESTree types from @typescript-eslint/types
    - Storage abstraction pattern for portability (@kotadb/core package)

    Does NOT cover MCP tool implementation (see MCP expert) or API routes.
  rationale: |
    Correct indexing enables code intelligence features (search, find usages, dependency analysis).
    Poor AST handling causes silent failures. KotaDB uses @typescript-eslint/parser for modern
    TypeScript support and consistent AST structure across the codebase.

core_implementation:
  directory_structure:
    app/src/indexer/:
      purpose: Core indexing modules
      ast-parser.ts: AST parsing wrapper using @typescript-eslint/parser
      ast-types.ts: TypeScript type definitions for AST nodes
      symbol-extractor.ts: Visitor pattern for symbol extraction
      reference-extractor.ts: Visitor pattern for reference extraction
      import-resolver.ts: Import path resolution utilities
      dependency-extractor.ts: Dependency graph construction
      circular-detector.ts: Circular dependency detection algorithms
      storage.ts: SQLite storage layer with transactional writes
      repos.ts: Repository management functions
      extractors.ts: High-level extraction orchestration
      parsers.ts: File type detection and parsing coordination
    
    packages/core/:
      purpose: Standalone @kotadb/core package (zero DB dependencies)
      src/parsers/: AST parsing modules
      src/analysis/: Symbol, reference, dependency extraction
      src/storage/: Storage abstraction (Memory + SQLite adapters)
      src/types/: Type definitions for symbols, references, dependencies
      tests/: Comprehensive test suite with real fixtures

  key_files:
    - path: app/src/indexer/ast-parser.ts
      purpose: AST parsing with graceful error handling
      exports: parseFile, isSupportedForAST
    - path: app/src/indexer/symbol-extractor.ts
      purpose: Symbol extraction from AST
      exports: extractSymbols, Symbol, SymbolKind
    - path: app/src/indexer/reference-extractor.ts
      purpose: Reference extraction from AST
      exports: extractReferences, Reference, ReferenceType
    - path: app/src/indexer/import-resolver.ts
      purpose: Import path resolution
      exports: resolveImport, resolveExtensions, handleIndexFiles
    - path: app/src/indexer/dependency-extractor.ts
      purpose: Dependency graph construction
      exports: extractDependencies, DependencyEdge
    - path: app/src/indexer/storage.ts
      purpose: SQLite storage with atomic transactions
      exports: storeIndexedData, StorageResult
    - path: app/src/api/queries.ts
      purpose: FTS5 search with proper term escaping
      exports: searchFilesLocal, escapeFts5Term
    - path: packages/core/src/storage/sqlite-adapter.ts
      purpose: Storage abstraction for portability
      exports: SqliteStorageAdapter, MemoryStorageAdapter

key_operations:
  parse_ast:
    when: Parsing TypeScript/JavaScript source code to AST
    approach: |
      1. Check if file is supported using isSupportedForAST(filePath)
         - Supported extensions: .ts, .tsx, .js, .jsx, .cjs, .mjs
         - JSON files are NOT parsed (data files, not code)
      2. Call parseFile(filePath, content)
         - Uses @typescript-eslint/parser with modern settings
         - Returns TSESTree.Program on success
         - Returns null on parse error (graceful failure)
      3. Handle null result gracefully
         - Log warning with file path
         - Continue processing other files
         - Never throw on parse errors

      Parser configuration:
      ```typescript
      parse(content, {
        ecmaVersion: "latest",
        sourceType: "module",
        loc: true,        // Line/column information
        range: true,      // Character range
        comment: true,    // Preserve comments (for JSDoc)
        tokens: true,     // Preserve tokens
        filePath,         // For error messages
      });
      ```
    examples:
      - parseFile("src/utils.ts", content) -> TSESTree.Program | null
      - isSupportedForAST("data.json") -> false
    pitfalls:
      - what: Throwing on parse errors
        instead: Return null and log error
        reason: Single bad file should not halt indexing
      - what: Parsing JSON files
        instead: Skip JSON files in isSupportedForAST
        reason: JSON is not valid JavaScript program

  extract_symbols:
    when: Extracting functions, classes, interfaces, types from AST
    approach: |
      1. Call extractSymbols(ast, filePath)
      2. Visitor pattern traverses AST
      3. Dispatch based on node.type
         - FunctionDeclaration -> function symbol
         - ClassDeclaration -> class symbol + methods/properties
         - TSInterfaceDeclaration -> interface symbol
         - TSTypeAliasDeclaration -> type symbol
         - TSEnumDeclaration -> enum symbol
         - VariableDeclaration -> variable/constant (if exported)
         - ExportNamedDeclaration -> recurse into declaration
      4. Extract metadata for each symbol
         - name, kind, lineStart, lineEnd, columnStart, columnEnd
         - signature (for functions)
         - documentation (JSDoc extraction)
         - isExported (public API tracking)
         - isAsync, accessModifier (TypeScript features)

      VisitorContext tracks:
      - comments: TSESTree.Comment[] (for JSDoc extraction)
      - parent: TSESTree.Node | null (for export detection)
      - isExported: boolean (current export context)

      Symbol kinds:
      - function, class, interface, type, variable, constant, method, property, enum
    examples:
      - FunctionDeclaration with async -> isAsync: true
      - Class method with private -> accessModifier: "private"
    pitfalls:
      - what: Missing location data (node.loc undefined)
        instead: Guard with if (!node.loc) return
        reason: Some synthetic nodes lack position info
      - what: Extracting non-exported variables
        instead: Only extract exported variables
        reason: Reduces noise in symbol table

  extract_references:
    when: Extracting imports, calls, property access, type references from AST
    approach: |
      1. Call extractReferences(ast, filePath)
      2. Visitor pattern traverses all nodes recursively
      3. Dispatch based on node.type
         - ImportDeclaration -> import references
         - CallExpression -> function/method call references
         - MemberExpression -> property access references
         - TSTypeReference -> TypeScript type references
      4. Extract metadata for each reference
         - targetName, referenceType, lineNumber, columnNumber
         - metadata (importSource, importAlias, isMethodCall, etc.)

      Reference types:
      - import: Named, default, namespace, side-effect imports
      - call: Function calls, method calls
      - property_access: Member expressions (non-call)
      - type_reference: TypeScript type references

      Import handling:
      - Named: import { foo } from './module'
      - Default: import foo from './module'
      - Namespace: import * as foo from './module'
      - Side-effect: import './module'
      - Aliased: import { foo as bar } from './module'
    examples:
      - ImportDeclaration -> multiple Reference objects (one per specifier)
      - CallExpression with MemberExpression -> isMethodCall: true
    pitfalls:
      - what: Not visiting children after extracting reference
        instead: Always call visitChildren for nested references
        reason: Chained calls (obj.foo().bar()) have nested structures
      - what: Extracting computed properties
        instead: Skip computed properties (return null)
        reason: Cannot resolve obj[key] statically

  resolve_imports:
    when: Resolving import paths to absolute file paths
    approach: |
      1. Call resolveImport(importSource, fromFilePath, files)
      2. Skip non-relative imports (node_modules, absolute paths)
         - Only handle imports starting with ./ or ../
      3. Resolve relative to importing file's directory
      4. Try extension resolution
         - Check .ts, .tsx, .js, .jsx, .mjs, .cjs in order
      5. Try index file resolution
         - Check index.ts, index.tsx, index.js, index.jsx
      6. Return null if not found (graceful failure)

      Resolution priority:
      1. Exact path (if has extension)
      2. Path + .ts, .tsx, .js, .jsx, .mjs, .cjs
      3. Directory + index.ts, index.tsx, index.js, index.jsx

      Non-goals (out of scope):
      - tsconfig.json path mapping (paths, baseUrl)
      - node_modules resolution
      - Absolute imports (/foo, @scope/pkg)
      - Dynamic imports
    examples:
      - "./utils" -> "/repo/src/utils.ts"
      - "./api" -> "/repo/src/api/index.ts"
      - "lodash" -> null (node_modules, skip)
    pitfalls:
      - what: Resolving node_modules imports
        instead: Return null for non-relative imports
        reason: External dependencies handled separately
      - what: Using path.resolve (creates absolute paths)
        instead: Use path.join + path.normalize
        reason: Preserves relative path structure

  build_dependencies:
    when: Constructing file-to-file and symbol-to-symbol dependency graph
    approach: |
      1. Call extractDependencies(files, symbols, references, repositoryId)
      2. Build file dependencies from import references
         - Match importSource to resolved file path
         - Create DependencyEdge with fromFileId, toFileId
         - dependencyType: "file_import"
      3. Build symbol dependencies from call references
         - Find caller symbol (containing the call expression)
         - Find callee symbol (function being called)
         - Create DependencyEdge with fromSymbolId, toSymbolId
         - dependencyType: "symbol_usage"

      Helper functions:
      - buildFileDependencies: Import references -> file edges
      - buildSymbolDependencies: Call references -> symbol edges
      - findSymbolByLineNumber: Match line to enclosing symbol

      Ambiguous match handling:
      - Multiple symbols with same name -> prefer same-file match
      - No match found -> log debug, skip edge
      - Missing target -> log warning, continue
    examples:
      - import { foo } from './utils' -> file_import edge
      - foo() inside bar() -> symbol_usage edge from bar to foo
    pitfalls:
      - what: Failing on unresolved references
        instead: Log debug/warning and continue
        reason: External functions, built-ins won't resolve
      - what: Creating self-references
        instead: Skip if fromSymbolId === toSymbolId
        reason: Recursive calls are not useful dependencies

  store_indexed_data:
    when: Persisting extracted data to SQLite database
    approach: |
      1. Call storeIndexedData(repositoryId, files, symbols, references, dependencies)
      2. Single transaction wraps all operations (atomicity)
      3. Insert files and build file_path -> file_id mapping
      4. Insert symbols and build symbol_key -> symbol_id mapping
         - symbol_key format: "file_path::symbol_name::line_start"
      5. Insert references using file/symbol mappings
      6. Return StorageResult with counts

      Storage interface:
      - FileData: path, content, language, size_bytes, metadata
      - SymbolData: file_path, name, kind, line_start, line_end, signature, documentation
      - ReferenceData: source_file_path, target_symbol_key, line_number, reference_type
      - DependencyGraphEntry: from_file_path, to_file_path, dependency_type

      Transaction pattern:
      ```typescript
      db.transaction(() => {
        // All inserts here are atomic
        // Rollback on any failure
      });
      ```
    examples:
      - storeIndexedData(repoId, files, symbols, refs, deps) -> { files_indexed: 10, ... }
    pitfalls:
      - what: Multiple separate transactions
        instead: Single transaction for all operations
        reason: Atomicity guarantees consistency
      - what: Missing file_id lookup for symbol
        instead: Log warning and skip symbol
        reason: Orphan symbols without file reference are useless

  search_indexed_content:
    when: Searching indexed file content with FTS5 full-text search
    approach: |
      1. Accept raw search term from user input
      2. Call escapeFts5Term(term) to sanitize for FTS5 MATCH
         - Escapes internal double quotes by doubling them
         - Wraps entire term in double quotes for exact phrase matching
      3. Use escaped term in FTS5 MATCH clause
         - Prevents operator interpretation (-, AND, OR, NOT)
         - Ensures multi-word phrases match as exact phrase
      4. Return search results with file path, content, and metadata
      
      Escaping pattern:
      ```typescript
      function escapeFts5Term(term: string): string {
        const escaped = term.replace(/"/g, '""');
        return `"${escaped}"`;
      }
      ```
      
      Common edge cases:
      - "pre-commit" → escaped prevents "no such column: commit" error
      - "planType smb" → matches exact phrase, not "planType AND smb"
      - "search and find" → "and" treated as literal, not AND operator
      - 'say "hello"' → embedded quotes doubled to 'say ""hello""'
    examples:
      - escapeFts5Term("pre-commit") → '"pre-commit"'
      - escapeFts5Term("planType smb") → '"planType smb"'
      - FTS5 MATCH with escaped term returns exact phrase matches
    pitfalls:
      - what: Using raw user input directly in MATCH clause
        instead: Always escape with escapeFts5Term
        reason: Hyphens interpreted as NOT, spaces as AND
      - what: Escaping with backslashes (\")
        instead: Double internal quotes ("")
        reason: SQLite FTS5 uses doubling for quote escaping
    timestamp: 2026-01-28
    evidence: commit 5af086f, app/src/api/queries.ts


  batch_process_large_repos:
    when: Indexing repositories with 200+ files to avoid database transaction timeouts
    approach: |
      1. Chunk files array into batches (BATCH_SIZE = 50 files)
      2. Process chunks sequentially with atomic transactions per chunk
      3. For first chunk: perform full DELETE+INSERT (skipDelete=false)
      4. For subsequent chunks: skip DELETE phase (skipDelete=true)
      5. Filter symbols, references, dependencies per chunk by file_path
      6. Accumulate stats across chunks for final reporting
      7. Update job progress metadata after each chunk completion
      
      Chunking pattern:
      ```typescript
      const chunks: FileData[][] = [];
      for (let i = 0; i < files.length; i += BATCH_SIZE) {
        chunks.push(files.slice(i, i + BATCH_SIZE));
      }
      
      for (let chunkIndex = 0; chunkIndex < chunks.length; chunkIndex++) {
        const chunk = chunks[chunkIndex];
        const skipDelete = chunkIndex > 0; // Only DELETE on first chunk
        
        // Filter data for this chunk
        const chunkFilePaths = new Set(chunk.map(f => f.path));
        const chunkSymbols = symbols.filter(s => chunkFilePaths.has(s.file_path));
        const chunkReferences = references.filter(r => chunkFilePaths.has(r.source_file_path));
        const chunkDependencies = deps.filter(d => d.from_file_path && chunkFilePaths.has(d.from_file_path));
        
        // Store chunk atomically
        await storeIndexedData(db, repoId, chunk, chunkSymbols, chunkReferences, chunkDependencies, skipDelete);
      }
      ```
      
      Key benefits:
      - Each chunk commits within transaction timeout limits
      - First chunk DELETE removes stale data
      - Subsequent chunks only INSERT new data
      - Progress tracking enables observability
      - Failed chunks don't affect completed chunks
    examples:
      - 250-file repository -> 5 chunks of 50 files each
      - Each chunk commits atomically in separate transaction
      - Progress metadata: chunks_completed, current_chunk
    pitfalls:
      - what: Deleting on every chunk
        instead: Only DELETE on first chunk (skipDelete parameter)
        reason: Repeated DELETEs cause conflicts and performance issues
      - what: Single transaction for entire large repo
        instead: Batch into chunks with separate transactions
        reason: Large transactions timeout on SQLite
      - what: Not filtering symbols/references per chunk
        instead: Filter by file_path Set for each chunk
        reason: Orphaned data references files not in chunk
    timestamp: 2026-01-28
    evidence: commit d47a650, app/src/queue/workers/index-repo.ts

  filter_build_artifacts:
    when: Discovering source files to avoid indexing build output and dependencies
    approach: |
      Maintain comprehensive IGNORED_DIRECTORIES set covering:
      
      Version control:
      - .git
      
      Package managers:
      - node_modules (JS/TS)
      - vendor (Go, Ruby, PHP)
      
      Build output:
      - build, dist, out
      - target (Rust, Java/Maven)
      
      Framework-specific build/cache:
      - .next, .vercel, .turbo (Next.js, Vercel, Turborepo)
      - .nuxt, .output (Nuxt.js)
      - .svelte-kit (SvelteKit)
      - .angular, .vite, .parcel-cache
      - .nx (Nx monorepo)
      
      Test coverage:
      - coverage
      
      Python:
      - __pycache__, .pytest_cache
      - venv, .venv, env
      
      General cache:
      - .cache
      
      Result: 27 ignored directories (expanded from original 7)
      Ensures only source files indexed, not generated code or dependencies.
    examples:
      - .next directory skipped for Next.js projects
      - venv directory skipped for Python projects
      - target directory skipped for Rust/Java projects
    pitfalls:
      - what: Incomplete ignored directories list
        instead: Cover all modern build tools and package managers
        reason: Build artifacts inflate index and add noise
      - what: Hardcoding list in multiple places
        instead: Single IGNORED_DIRECTORIES constant
        reason: Maintainability and consistency
    timestamp: 2026-01-28
    evidence: commit 5a4bca3, app/src/indexer/parsers.ts

decision_trees:
  ast_parsing_strategy:
    question: How should I parse this file?
    options:
      - if: File extension is .ts, .tsx, .js, .jsx, .cjs, .mjs
        then: Use parseFile() to get AST
      - if: File extension is .json
        then: Skip AST parsing (data file)
      - if: File extension is unknown
        then: Check isSupportedForAST(), skip if false
      - if: parseFile() returns null
        then: Log warning, continue with other files

  symbol_extraction_approach:
    question: What kind of symbol is this AST node?
    options:
      - if: FunctionDeclaration
        then: Extract function symbol with signature
      - if: ClassDeclaration
        then: Extract class symbol, recurse into methods/properties
      - if: TSInterfaceDeclaration
        then: Extract interface symbol
      - if: TSTypeAliasDeclaration
        then: Extract type symbol
      - if: TSEnumDeclaration
        then: Extract enum symbol
      - if: VariableDeclaration and isExported
        then: Extract variable/constant/function symbol
      - if: ExportNamedDeclaration or ExportDefaultDeclaration
        then: Recurse into declaration with isExported: true
      - if: Other node type
        then: Skip (no symbol to extract)

  reference_extraction_approach:
    question: What kind of reference is this AST node?
    options:
      - if: ImportDeclaration
        then: Extract import reference per specifier
      - if: CallExpression with Identifier callee
        then: Extract function call reference
      - if: CallExpression with MemberExpression callee
        then: Extract method call reference
      - if: MemberExpression (not callee of CallExpression)
        then: Extract property access reference
      - if: TSTypeReference
        then: Extract type reference
      - if: Other node type
        then: Visit children recursively

  import_resolution_strategy:
    question: How should I resolve this import path?
    options:
      - if: Starts with ./ or ../
        then: Relative import, resolve with extensions/index files
      - if: Starts with / or @ scope
        then: Absolute import, return null (out of scope)
      - if: No prefix (bare module)
        then: Node modules import, return null (out of scope)
      - if: Has extension already
        then: Check exact path in files Set
      - if: No extension
        then: Try SUPPORTED_EXTENSIONS in order
      - if: Still not found
        then: Try index file resolution

patterns:
  visitor_pattern:
    structure: |
      function visitNode(node, results, context): void {
        // Update context for children
        const childContext = { ...context, parent: node };

        // Dispatch based on node type
        switch (node.type) {
          case "SpecificNodeType":
            extractFromNode(node, results, context);
            break;
          default:
            visitChildren(node, results, childContext);
        }
      }

      function visitChildren(node, results, context): void {
        for (const key of Object.keys(node)) {
          const value = node[key];
          if (isNode(value)) {
            visitNode(value, results, context);
          } else if (Array.isArray(value)) {
            for (const child of value) {
              if (isNode(child)) {
                visitNode(child, results, context);
              }
            }
          }
        }
      }
    trade_offs:
      pros: [Flexible traversal, Easy to extend, Clear dispatch logic]
      cons: [Recursive stack depth, Manual child handling]

  graceful_error_handling:
    structure: |
      try {
        const result = parse(content, options);
        return result;
      } catch (error) {
        logger.error("Failed to parse", error, {
          file_path: filePath,
          parse_error: error.message,
        });
        Sentry.captureException(error, { tags: { module: "ast-parser" } });
        return null;  // Graceful failure
      }
    trade_offs:
      pros: [Resilient indexing, Observability via logs/Sentry]
      cons: [Some files not indexed, Potential silent failures]

  transactional_storage:
    structure: |
      db.transaction(() => {
        // Build lookup maps
        const pathToId = new Map();

        // Insert files, populate map
        for (const file of files) {
          const id = insert(file);
          pathToId.set(file.path, id);
        }

        // Insert symbols using file map
        for (const symbol of symbols) {
          const fileId = pathToId.get(symbol.file_path);
          insert({ ...symbol, file_id: fileId });
        }

        // All or nothing - rollback on failure
      });
    trade_offs:
      pros: [Atomicity, Consistency, No partial state]
      cons: [All-or-nothing (large batch failures)]

  jsdoc_extraction:
    structure: |
      function extractLeadingComment(node, comments): string | null {
        // Find last block comment before node within 5 lines
        for (const comment of comments) {
          if (comment.type !== "Block") continue;
          if (comment.loc.end.line >= node.loc.start.line) continue;
          if (node.loc.start.line - comment.loc.end.line > 5) continue;
          // Keep closest match
        }
        // Strip /** */ and leading * from each line
        return cleanedText;
      }
    trade_offs:
      pros: [Preserves documentation, Position-based matching]
      cons: [5-line heuristic may miss some comments]

  storage_abstraction:
    structure: |
      // Define interface for storage operations
      interface StorageAdapter {
        storeSymbols(symbols: Symbol[]): Promise<void>;
        storeReferences(refs: Reference[]): Promise<void>;
        storeDependencies(deps: DependencyEdge[]): Promise<void>;
      }
      
      // Implement concrete adapters
      class MemoryStorageAdapter implements StorageAdapter { ... }
      class SqliteStorageAdapter implements StorageAdapter { ... }
      
      // Use dependency injection
      function analyzeCode(files: File[], storage: StorageAdapter) {
        const symbols = extractSymbols(files);
        await storage.storeSymbols(symbols);
      }
    trade_offs:
      pros: [Zero infrastructure dependencies, Testable with in-memory storage, Portable across environments]
      cons: [Additional abstraction layer, Interface evolution complexity]
    timestamp: 2026-01-28
    evidence: commit 1eab8bc, packages/core/src/storage/


  batch_transaction_pattern:
    structure: |
      // Chunk large datasets for atomic batch processing
      const BATCH_SIZE = 50;
      const chunks = chunkArray(items, BATCH_SIZE);
      
      let totalProcessed = 0;
      
      for (let i = 0; i < chunks.length; i++) {
        const chunk = chunks[i];
        const isFirstChunk = i === 0;
        
        // Process chunk in single transaction
        db.transaction(() => {
          // First chunk: full cleanup + insert
          if (isFirstChunk) {
            db.run("DELETE FROM table WHERE ...");
          }
          
          // All chunks: insert new data
          for (const item of chunk) {
            db.run("INSERT INTO table ...", item);
          }
        });
        
        totalProcessed += chunk.length;
        
        // Update progress
        reportProgress(totalProcessed, items.length);
      }
    trade_offs:
      pros: [Avoids transaction timeouts, Atomic per-chunk commits, Progress tracking, Partial success on failure]
      cons: [More complex than single transaction, Multiple database round-trips, Partial state if interrupted]
    timestamp: 2026-01-28
    evidence: commit d47a650

best_practices:
  ast_parsing:
    - Use @typescript-eslint/parser for modern TypeScript support
    - Always enable loc, range, comment, tokens options
    - Return null on parse error (never throw)
    - Log errors with file path for debugging
    - Check isSupportedForAST before parsing

  symbol_extraction:
    - Use visitor pattern for consistent traversal
    - Track export context through visitor context
    - Extract JSDoc comments for documentation
    - Include position info (line/column) for navigation
    - Handle anonymous functions gracefully (<anonymous>)

  reference_extraction:
    - Visit children after extracting reference (for nested references)
    - Skip computed properties (cannot resolve statically)
    - Distinguish function calls from method calls
    - Track optional chaining (?.) in metadata

  import_resolution:
    - Only resolve relative imports (./ and ../)
    - Try extensions in priority order (.ts first)
    - Handle index file resolution
    - Return null for unresolvable imports (graceful)
    - Use path.join + path.normalize (NOT path.resolve)
    - Preserve relative path structure for database matching
    timestamp: 2026-01-28
  storage:
    - Use single transaction for atomicity
    - Build lookup maps for efficient foreign key resolution
    - Generate UUIDs for primary keys
    - Log storage results for observability

  fts5_search:
    - Always escape user search terms before FTS5 MATCH queries
    - Wrap terms in double quotes for exact phrase matching
    - Escape internal quotes by doubling them ("" not \")
    - Prevents SQL errors on hyphens, spaces, AND/OR/NOT keywords
    - Test with: hyphenated-terms, multi-word phrases, FTS keywords
    timestamp: 2026-01-28
    evidence: commit 5af086f

  logging:
    - Use createLogger({ module: "indexer-<name>" })
    - Log errors with structured metadata
    - Use debug level for expected failures (unresolved imports)
    - Use warn level for unexpected but recoverable failures
    - Never use console.* (use process.stdout.write for raw output)

known_issues:
  - issue: path.resolve() converts relative to absolute paths
    impact: Import resolution fails when database stores relative paths
    resolution: Use path.join() + path.normalize() to preserve relative structure
    prevention: |
      Never use path.resolve() in import resolution.
      Always use: path.normalize(path.join(fromDir, importSource))
      This preserves relative paths matching database storage format.
    status: resolved
    timestamp: 2026-01-28
    evidence: commit 5713a52, app/src/indexer/import-resolver.ts

  - issue: tsconfig.json path mapping not supported
    impact: Absolute imports with path aliases not resolved
    resolution: Only relative imports currently supported
    prevention: Document limitation, plan future enhancement
    status: known limitation

  - issue: Dynamic imports not tracked
    impact: import() expressions not in dependency graph
    resolution: Could add CallExpression with import callee handling
    prevention: Document limitation
    status: known limitation

  - issue: Type-only imports not distinguished
    impact: import type { Foo } treated same as import { Foo }
    resolution: Could check importKind in TSESTree
    prevention: Minor impact on dependency analysis
    status: low priority

  - issue: Overloaded functions create multiple symbols
    impact: Same name appears multiple times in symbol table
    resolution: Could merge by name and deduplicate
    prevention: Acceptable for now, may confuse "find usages"
    status: known limitation

  - issue: Schema CHECK constraint must match all reference types
    impact: Insertion failures when reference extractor produces new types
    resolution: property_access was missing from CHECK constraint list
    prevention: |
      When adding new reference types:
      1. Update reference extractor enum/type
      2. Update SQLite schema CHECK constraint
      3. Add integration test for new type
    status: resolved
    timestamp: 2026-01-28
    evidence: commit 91415ad

potential_enhancements:
  - enhancement: tsconfig.json path mapping support
    rationale: Enable resolution of @alias/* imports
    effort: medium
    approach: Parse tsconfig.json, apply paths mapping in resolveImport

  - enhancement: Dynamic import tracking
    rationale: Complete dependency graph for code splitting
    effort: low
    approach: Handle CallExpression with import callee

  - enhancement: Call graph visualization
    rationale: Visual dependency analysis
    effort: medium
    approach: Generate DOT format from dependency graph

  - enhancement: Incremental indexing
    rationale: Faster re-indexing for changed files only
    effort: high
    approach: Track file hashes, re-index only changed files

  - enhancement: Cross-repository symbol resolution
    rationale: Find usages across multiple repositories
    effort: high
    approach: Global symbol index with repository context

  - enhancement: Extract @kotadb/core as standalone package
    rationale: Enable code analysis in other tools without DB dependencies
    effort: completed
    approach: Storage abstraction with MemoryAdapter and SqliteAdapter
    status: implemented
    timestamp: 2026-01-28
    evidence: commit 1eab8bc, packages/core/

stability:
  convergence_indicators:
    insight_rate_trend: stable
    contradiction_count: 0
    new_patterns_added_this_cycle: 5
    patterns_updated_this_cycle: 1
    last_reviewed: 2026-01-28
    utility_ratio: 1.0
    notes: |
      Cycle 2 update - added batch processing and build artifact filtering:
      - Previous: FTS5 term escaping, storage abstraction, schema validation
      - New: Batch processing for large repos, build artifact filtering (27 dirs)
      - New: Path resolution fix (path.join + normalize vs resolve)
      - Updated: @kotadb/core extraction completed with storage abstraction
      - Storage abstraction pattern from @kotadb/core extraction
      - Schema constraint validation alignment
      - Updated local-only v2 architecture patterns
