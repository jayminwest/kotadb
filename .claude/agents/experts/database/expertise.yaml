# Database Expertise for KotaDB
# Target: 400-600 lines | Domain: SQLite schema design, FTS5 search, local-only architecture
# Adapted for KotaDB local-first v2 architecture

overview:
  description: |
    SQLite database expertise for KotaDBâ€”local-only code intelligence storage using
    SQLite with FTS5 full-text search, WAL mode for concurrency, and type-safe TypeScript
    wrappers. This expertise enables correct database schema design, query optimization,
    and migration management within the KotaDB local-first architecture.
  scope: |
    Covers SQLite schema at app/src/db/sqlite-schema.sql, database client at 
    app/src/db/sqlite/sqlite-client.ts, query layer at app/src/api/queries.ts,
    FTS5 full-text search patterns, dependency graph recursive CTEs, WAL mode
    configuration, connection pooling, and migration strategies.

    KOTADB DATABASE ARCHITECTURE:
    - Local-only SQLite storage (no Supabase, no cloud)
    - Database location: ~/.kotadb/kota.db (or KOTADB_PATH env var)
    - WAL mode enabled for concurrent reads/writes
    - FTS5 for code search with external content tables
    - Connection pool pattern: 1 writer + N readers
    - Type mappings: uuid->TEXT, timestamptz->TEXT(ISO8601), jsonb->TEXT, boolean->INTEGER

    Does NOT cover cloud database patterns or Supabase (removed in v2).
  rationale: |
    Correct database design enables fast code search, reliable dependency tracking,
    and safe concurrent access. Poor schema design leads to slow queries, data
    corruption, and difficult migrations. KotaDB's local-first architecture requires
    specialized SQLite patterns that differ from cloud database approaches.

core_implementation:
  database_location:
    primary: ~/.kotadb/kota.db
    environment_override: KOTADB_PATH
    resolution_order:
      - Explicit config path
      - KOTADB_PATH environment variable
      - Default ~/.kotadb/kota.db
    directory_creation: Automatic via sqlite-client.ts

  key_files:
    - path: app/src/db/sqlite-schema.sql
      purpose: Complete SQLite schema with FTS5, triggers, and indexes
      tables:
        - repositories (git repository metadata)
        - indexed_files (source files with FTS5 search)
        - indexed_symbols (functions, classes, types)
        - indexed_references (import/call relationships)
        - projects (user-defined groupings)
        - project_repositories (many-to-many junction)
        - dependency_graph (file and symbol dependencies)
        - schema_migrations (migration tracking)
    - path: app/src/db/sqlite/sqlite-client.ts
      purpose: Type-safe KotaDatabase class and ConnectionPool
      exports:
        - KotaDatabase (single connection wrapper)
        - ConnectionPool (1 writer + N readers)
        - getGlobalDatabase() (singleton access)
        - getGlobalPool() (pool singleton)
    - path: app/src/api/queries.ts
      purpose: Query layer with FTS5 search and dependency traversal
      functions:
        - searchFiles() (FTS5 full-text search)
        - saveIndexedFiles() (batch insert with transactions)
        - queryDependents() (recursive CTE for dependents)
        - queryDependencies() (recursive CTE for dependencies)

  schema_design_principles:
    type_mappings:
      uuid: TEXT (RFC 4122 format, 36 chars)
      timestamptz: TEXT (ISO 8601 format)
      jsonb: TEXT (JSON string, use JSON1 extension)
      boolean: INTEGER (0 = false, 1 = true)
      text_array: TEXT (JSON array string)
    constraints:
      primary_keys: TEXT UUIDs generated via randomUUID()
      foreign_keys: ON DELETE CASCADE for referential integrity
      unique_indexes: Partial indexes where needed (WHERE clause)
      check_constraints: For enum-like columns (kind, reference_type)

key_operations:
  design_fts5_search:
    when: Implementing full-text search on file content
    approach: |
      1. Create external content FTS5 table linked to base table:
         ```sql
         CREATE VIRTUAL TABLE IF NOT EXISTS indexed_files_fts USING fts5(
             path,
             content,
             content='indexed_files',
             content_rowid='rowid'
         );
         ```
      2. Create sync triggers for INSERT, UPDATE, DELETE:
         - AFTER INSERT: Add new content to FTS
         - AFTER DELETE: Remove using 'delete' command
         - AFTER UPDATE: Delete old, insert new
      3. Query using MATCH with bm25() ranking:
         ```sql
         SELECT f.*, snippet(indexed_files_fts, 1, '<mark>', '</mark>', '...', 32) AS snippet
         FROM indexed_files_fts fts
         JOIN indexed_files f ON fts.rowid = f.rowid
         WHERE indexed_files_fts MATCH ?
         ORDER BY bm25(indexed_files_fts)
         LIMIT ?
         ```
      4. Escape user input for FTS5 (wrap in quotes, escape internal quotes)
    pitfalls:
      - what: "Using FTS5 without external content table"
        instead: "Use content='' to avoid duplicate storage"
        reason: "Doubles storage requirements and sync overhead"
      - what: "Not escaping FTS5 queries"
        instead: "Use escapeFts5Term() wrapper for user input"
        reason: "Hyphens and FTS5 keywords cause syntax errors"

  create_migration:
    when: Adding new tables, columns, or indexes
    approach: |
      1. Check current schema version via PRAGMA user_version
      2. Create migration SQL with IF NOT EXISTS guards:
         ```sql
         CREATE TABLE IF NOT EXISTS new_table (...);
         CREATE INDEX IF NOT EXISTS idx_name ON table(column);
         ```
      3. Use transactions for multi-statement migrations:
         ```typescript
         db.transaction(() => {
           db.exec(migrationSQL);
           db.setSchemaVersion(newVersion);
         });
         ```
      4. Record migration in schema_migrations table
      5. Test rollback strategy before applying
    kotadb_conventions:
      - Use PRAGMA user_version for version tracking
      - Insert into schema_migrations for audit trail
      - Use IF NOT EXISTS for idempotent migrations
      - Apply in sqlite-client.ts constructor if needed

  optimize_query:
    when: Query performance is slow or EXPLAIN shows full table scans
    approach: |
      1. Analyze query plan:
         ```sql
         EXPLAIN QUERY PLAN SELECT ... FROM ...
         ```
      2. Check for missing indexes on WHERE, JOIN, ORDER BY columns
      3. Add composite indexes for multi-column queries:
         ```sql
         CREATE INDEX IF NOT EXISTS idx_composite ON table(col1, col2);
         ```
      4. Use covering indexes when reading only indexed columns
      5. Consider partial indexes for frequently filtered subsets:
         ```sql
         CREATE INDEX IF NOT EXISTS idx_partial ON table(col) WHERE condition;
         ```
      6. For FTS5, ensure content sync triggers are efficient
    common_optimizations:
      - Add index on foreign key columns (repository_id, file_id)
      - Use prepared statements for repeated queries
      - Batch inserts within transactions
      - Use IMMEDIATE transactions for write operations

  implement_recursive_cte:
    when: Traversing dependency graphs or hierarchical data
    approach: |
      1. Define base case (initial selection):
         ```sql
         WITH RECURSIVE deps AS (
             SELECT id, target_id, 1 AS depth, '/' || id || '/' AS path
             FROM dependency_graph
             WHERE source_id = ?
         ```
      2. Define recursive case (join to CTE):
         ```sql
             UNION ALL
             SELECT d.id, d.target_id, deps.depth + 1, deps.path || d.id || '/'
             FROM dependency_graph d
             JOIN deps ON d.source_id = deps.target_id
             WHERE deps.depth < ? AND INSTR(deps.path, '/' || d.id || '/') = 0
         )
         ```
      3. Add cycle detection via path column (INSTR check)
      4. Limit depth to prevent infinite recursion
      5. Select from CTE with appropriate joins:
         ```sql
         SELECT DISTINCT d.*, f.path AS file_path
         FROM deps d
         LEFT JOIN indexed_files f ON d.target_id = f.id
         ORDER BY d.depth
         ```
    patterns:
      - queryDependents(): Find files that depend ON target
      - queryDependencies(): Find files that target DEPENDS on
      - Cycle detection: Track visited IDs in path string

  configure_wal_mode:
    when: Setting up database for concurrent access
    approach: |
      1. Enable WAL mode (writer connection only):
         ```sql
         PRAGMA journal_mode = WAL;
         ```
      2. Configure busy timeout for lock contention:
         ```sql
         PRAGMA busy_timeout = 30000;
         ```
      3. Set performance pragmas:
         ```sql
         PRAGMA synchronous = NORMAL;
         PRAGMA cache_size = -64000;  -- 64MB cache
         PRAGMA temp_store = MEMORY;
         PRAGMA mmap_size = 268435456;  -- 256MB mmap
         ```
      4. Enable foreign key enforcement:
         ```sql
         PRAGMA foreign_keys = ON;
         ```
      5. Checkpoint periodically:
         ```sql
         PRAGMA wal_checkpoint(TRUNCATE);
         ```
    connection_pool_pattern:
      writer: Single connection with WAL mode, read-write
      readers: N connections (CPU count) with read-only mode
      usage: getWriter() for writes, getReader() for reads

decision_trees:
  fts5_vs_like:
    question: Should I use FTS5 or LIKE for search?
    options:
      - if: Searching file content (code search)
        then: Use FTS5 with indexed_files_fts table
        reason: "FTS5 provides ranking, snippets, and O(log n) performance"
      - if: Searching exact column values (paths, names)
        then: Use LIKE with index on column
        reason: "Simpler query, no sync triggers needed"
      - if: Searching with complex patterns (regex-like)
        then: Use LIKE '%pattern%' with full scan
        reason: "FTS5 doesn't support arbitrary patterns"

  index_type_selection:
    question: What type of index should I create?
    options:
      - if: Single column equality queries (WHERE col = ?)
        then: Standard B-tree index (CREATE INDEX)
      - if: Multi-column queries with leading column filter
        then: Composite index with most selective column first
      - if: Frequent queries on subset of rows
        then: Partial index with WHERE clause
      - if: Full-text search on text content
        then: FTS5 virtual table with sync triggers
      - if: JSON field access
        then: Expression index on json_extract()

  migration_strategy:
    question: How should I apply this schema change?
    options:
      - if: Adding new table
        then: CREATE TABLE IF NOT EXISTS (idempotent)
      - if: Adding new column
        then: ALTER TABLE ADD COLUMN with default value
      - if: Modifying column type
        then: Create new column, migrate data, drop old (SQLite limitation)
      - if: Adding index
        then: CREATE INDEX IF NOT EXISTS (idempotent)
      - if: Changing table structure significantly
        then: Rename old, create new, migrate data, drop old

  transaction_type:
    question: Which transaction type should I use?
    options:
      - if: Read-only query
        then: No explicit transaction (autocommit)
      - if: Single write operation
        then: db.run() with autocommit
      - if: Multiple related writes
        then: db.transaction(() => { ... })
      - if: Write that must not fail due to other writers
        then: db.immediateTransaction(() => { ... })

patterns:
  external_content_fts5:
    structure: |
      -- Base table with actual data
      CREATE TABLE content_table (
          id TEXT PRIMARY KEY,
          searchable_text TEXT NOT NULL,
          metadata TEXT
      );
      
      -- External content FTS5 (no duplicate storage)
      CREATE VIRTUAL TABLE content_fts USING fts5(
          searchable_text,
          content='content_table',
          content_rowid='rowid'
      );
      
      -- Sync triggers (INSERT, DELETE, UPDATE)
      CREATE TRIGGER content_fts_ai AFTER INSERT ON content_table BEGIN
          INSERT INTO content_fts(rowid, searchable_text) VALUES (new.rowid, new.searchable_text);
      END;
      
      CREATE TRIGGER content_fts_ad AFTER DELETE ON content_table BEGIN
          INSERT INTO content_fts(content_fts, rowid, searchable_text) 
          VALUES ('delete', old.rowid, old.searchable_text);
      END;
      
      CREATE TRIGGER content_fts_au AFTER UPDATE ON content_table BEGIN
          INSERT INTO content_fts(content_fts, rowid, searchable_text) 
          VALUES ('delete', old.rowid, old.searchable_text);
          INSERT INTO content_fts(rowid, searchable_text) VALUES (new.rowid, new.searchable_text);
      END;
    trade_offs:
      pros: [No duplicate storage, Automatic sync, Fast full-text search]
      cons: [Trigger overhead on writes, FTS5 query syntax learning curve]

  connection_pool:
    structure: |
      // 1 writer for all write operations
      const writer = new KotaDatabase({ readonly: false, wal: true });
      
      // N readers for concurrent read operations
      const readers = Array(cpus().length).fill(null).map(() =>
        new KotaDatabase({ readonly: true, wal: true })
      );
      
      // Round-robin reader selection
      function getReader(): KotaDatabase {
        const reader = readers[readerIndex];
        readerIndex = (readerIndex + 1) % readers.length;
        return reader;
      }
    usage: |
      pool.write(db => db.run('INSERT ...'));
      pool.read(db => db.query('SELECT ...'));
    trade_offs:
      pros: [Concurrent reads, Single writer prevents conflicts, WAL benefits]
      cons: [Memory overhead, Connection management complexity]

  batch_insert_pattern:
    structure: |
      function batchInsert(db: KotaDatabase, records: Record[]) {
        db.transaction(() => {
          const stmt = db.prepare('INSERT INTO table (col1, col2) VALUES (?, ?)');
          for (const record of records) {
            stmt.run([record.col1, record.col2]);
          }
        });
      }
    notes:
      - Prepare statement once, reuse for all inserts
      - Wrap in transaction for atomicity and performance
      - Use IMMEDIATE transaction if concurrent writers possible

  uuid_generation:
    approach: |
      import { randomUUID } from "node:crypto";
      const id = randomUUID();  // Standard RFC 4122 UUID
    storage: TEXT column (36 characters)
    indexing: Primary key index automatically created

best_practices:
  schema_design:
    - Use TEXT for UUIDs (36 chars, RFC 4122 format)
    - Use TEXT with ISO 8601 for timestamps (sortable)
    - Use TEXT for JSON (parse with JSON1 extension)
    - Use INTEGER for booleans (0/1)
    - Add CHECK constraints for enum-like columns
    - Create indexes on foreign key columns
    - Use ON DELETE CASCADE for referential integrity

  query_layer:
    - Use parameterized queries (never string interpolation)
    - Prepare statements for repeated queries
    - Batch inserts within transactions
    - Use IMMEDIATE transactions for writes
    - Escape FTS5 queries before MATCH

  connection_management:
    - Use connection pool for concurrent access
    - Single writer, multiple readers pattern
    - Enable WAL mode for better concurrency
    - Set appropriate busy_timeout (30s default)
    - Close connections on shutdown

  performance:
    - Use covering indexes when possible
    - Use partial indexes for filtered queries
    - Batch operations within transactions
    - Use EXPLAIN QUERY PLAN to diagnose
    - Checkpoint WAL periodically

  migrations:
    - Use IF NOT EXISTS for idempotent migrations
    - Track schema version via PRAGMA user_version
    - Record migrations in schema_migrations table
    - Test rollback strategy before applying
    - Avoid data-destructive migrations

known_issues:
  - issue: FTS5 MATCH syntax errors with hyphens
    impact: Queries like "mom-and-pop" fail with syntax error
    resolution: Wrap user input in quotes via escapeFts5Term()
    status: Implemented in queries.ts

  - issue: SQLite column type changes not supported
    impact: Cannot ALTER COLUMN type in SQLite
    resolution: Create new column, migrate data, drop old column
    status: Design pattern documented

  - issue: WAL mode requires file system support
    impact: Network file systems may not support WAL
    resolution: Use default journal mode on unsupported systems
    status: Check file system compatibility

  - issue: Large transactions can cause WAL growth
    impact: WAL file grows until checkpoint
    resolution: Checkpoint periodically, batch in smaller transactions
    status: Checkpoint implemented in sqlite-client.ts

potential_enhancements:
  - Add database backup/restore functionality
  - Implement incremental FTS5 index updates
  - Add query plan caching for complex CTEs
  - Implement database compaction (VACUUM) scheduling
  - Add schema diff tool for migration generation
  - Implement read replica support for distributed queries

stability:
  convergence_indicators:
    insight_rate_trend: initial
    contradiction_count: 0
    new_patterns_added_this_cycle: 0
    patterns_updated_this_cycle: 0
    last_reviewed: 2026-01-28
    utility_ratio: 1.0
    notes: |
      Initial expertise creation for database domain.
      Based on KotaDB v2 local-only architecture.
      SQLite schema finalized in feature-532 (local-first).
      Query layer implemented in feature-539 (Phase 2b).
