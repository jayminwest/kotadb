# Testing Setup Guide

This document explains how to set up and run the KotaDB test suite with a real PostgreSQL test database.

## Overview

KotaDB follows an **antimocking philosophy** - tests use real database connections instead of mocks. This provides:

- Production parity testing
- Real connection/timeout/RLS behavior
- No mock maintenance burden
- True confidence in database interactions

## Prerequisites

- **Docker**: For running the PostgreSQL test database container
- **Bun**: v1.1+ for running tests
- **Supabase CLI**: For managing local Supabase services
- **jq**: JSON parsing tool for auto-generating `.env.test`
- **psql**: PostgreSQL client (for manual database inspection, optional)

### Install Prerequisites (macOS)

```bash
brew install supabase/tap/supabase jq
```

For other platforms, see:
- [Supabase CLI Installation Guide](https://supabase.com/docs/guides/cli)
- [jq Downloads](https://jqlang.github.io/jq/download/)

## Quick Start

KotaDB uses **Supabase CLI** to manage local test infrastructure. The CLI handles Docker containers, migrations, and service orchestration automatically.

### 1. Start Test Database (First Time)

```bash
bun run test:setup
```

This script will:
- Check prerequisites (Supabase CLI, jq, Docker)
- Start Supabase Local services via `supabase start` (PostgreSQL, PostgREST, Kong, Auth)
- Auto-generate `.env.test` from `supabase status` output
- Run schema migrations automatically (from `supabase/migrations/`)
- Seed test data (users, API keys, repositories, indexed files)

**What happens:**
1. Supabase CLI starts Docker containers for all services
2. Migrations from `supabase/migrations/` are applied automatically
3. `generate-env-test.sh` extracts credentials and creates `.env.test`
4. Seed data is loaded from `supabase/seed.sql`

### 2. Run Tests

```bash
bun test
```

The test suite automatically loads environment variables from `.env.test` via a preload script (`app/tests/setup.ts`). No manual `export` or `source` commands are required - tests will automatically use credentials from the Docker Compose stack.

### 3. Check Service Status

```bash
bun run test:status
```

Shows all running Supabase services with ports and URLs.

### 4. Reset Database (Optional)

Between test runs, if you need a clean state:

```bash
bun run test:reset
```

This uses `supabase db reset` to truncate tables and re-seed test data.

### 5. Stop Services

When done testing:

```bash
bun run test:teardown
```

This stops all Supabase Local services (Docker containers remain for fast restarts).

## Auto-Generated .env.test

The `.env.test` file is **automatically generated** from Supabase CLI status and should **not be committed to git**.

### How It Works

The `scripts/generate-env-test.sh` script:
1. Runs `supabase status --output json`
2. Parses JSON output with `jq` to extract:
   - `SUPABASE_URL` (Kong gateway URL)
   - `SUPABASE_SERVICE_KEY` (JWT for service role)
   - `SUPABASE_ANON_KEY` (JWT for anonymous role)
   - `DATABASE_URL` (PostgreSQL connection string)
3. Writes `.env.test` with proper format

### Manual Regeneration

If you need to regenerate `.env.test` (e.g., after restarting Supabase):

```bash
bun run test:env
```

### Why Auto-Generate?

- **No manual configuration**: Credentials extracted automatically from running services
- **No stale credentials**: Always matches current Supabase Local instance
- **Easier onboarding**: New developers just run `bun run test:setup`
- **Security**: Auto-generated files reduce risk of committing secrets

### Fallback to Docker Compose (Advanced)

If you prefer raw Docker Compose without Supabase CLI, you can still use:

```bash
docker compose up -d supabase-db supabase-rest supabase-auth supabase-kong
```

However, you'll need to manually maintain `.env.test` with static credentials.

## Test Database Architecture

### Connection Details

- **Host**: localhost
- **Port**: 5434 (to avoid conflicts with local Postgres)
- **PostgREST API**: 54322 (direct API access)
- **Kong Gateway**: 54326 (used by Supabase JS client)
- **Studio UI**: 54328 (http://localhost:54328)
- **Database**: postgres
- **User**: postgres
- **Password**: postgres (auto-generated by Supabase CLI)

### Test Data

The database is seeded with deterministic test data (see `supabase/seed.sql`):

#### Test Users
- Free user: `00000000-0000-0000-0000-000000000001`
- Solo user: `00000000-0000-0000-0000-000000000002`
- Team user: `00000000-0000-0000-0000-000000000003`

#### Test API Keys
```typescript
// Free tier
kota_free_test1234567890ab_0123456789abcdef0123456789abcdef

// Solo tier
kota_solo_solo1234567890ab_0123456789abcdef0123456789abcdef

// Team tier
kota_team_team1234567890ab_0123456789abcdef0123456789abcdef

// Disabled (for testing disabled key handling)
kota_free_disabled12345678_0123456789abcdef0123456789abcdef
```

All test API keys use the same secret (`0123456789abcdef0123456789abcdef`) which is bcrypt-hashed in the database.

#### Test Repositories
- `testuser/test-repo` (user-owned)
- `solouser/solo-repo` (user-owned)
- `test-org/team-repo` (organization-owned)

### Schema

The test database uses the same schema as production:
- `auth.users` - Minimal auth schema for testing (mimics Supabase)
- `api_keys` - API key storage with bcrypt hashes
- `organizations` - Team workspaces
- `user_organizations` - Membership join table
- `repositories` - Git repositories
- `index_jobs` - Indexing job tracking
- `indexed_files` - Parsed source files
- `symbols`, `references`, `dependencies` - Code intelligence tables

## Writing Tests

### Using Test Helpers

Import test helpers from `tests/helpers/db.ts`:

```typescript
import { createAuthHeader, TEST_API_KEYS, TEST_USER_IDS } from "../helpers/db";

// Create auth header with test API key
const headers = {
  "Authorization": createAuthHeader("free"),  // or "solo", "team"
};

// Access test data IDs
const userId = TEST_USER_IDS.free;
const apiKey = TEST_API_KEYS.solo;
```

### Multi-User Testing for RLS

KotaDB enforces Row Level Security (RLS) to ensure users can only access their own data. Testing RLS requires creating test data for multiple users and verifying isolation.

**Test User Aliases:**
```typescript
import { TEST_USER_IDS, createTestJob, getTestApiKey } from "../helpers/db";

// Alice (free tier user)
const aliceUserId = TEST_USER_IDS.alice;  // Same as TEST_USER_IDS.free
const aliceApiKey = getTestApiKey("free");

// Bob (solo tier user)
const bobUserId = TEST_USER_IDS.bob;      // Same as TEST_USER_IDS.solo
const bobApiKey = getTestApiKey("solo");
```

**Creating Jobs for Specific Users:**
```typescript
// Create job for Alice
const aliceJobId = await createTestJob({
  userId: TEST_USER_IDS.alice,
  ref: "main",
  status: "pending"
});

// Create job for Bob
const bobJobId = await createTestJob({
  userId: TEST_USER_IDS.bob,
  ref: "feature-branch",
  status: "completed"
});
```

**Testing RLS Enforcement:**
```typescript
// Alice should see her own job
const aliceResponse = await fetch(`${BASE_URL}/jobs/${aliceJobId}`, {
  headers: { Authorization: `Bearer ${aliceApiKey}` }
});
expect(aliceResponse.status).toBe(200);

// Bob should NOT see Alice's job (404, not 403 to prevent existence leakage)
const bobResponse = await fetch(`${BASE_URL}/jobs/${aliceJobId}`, {
  headers: { Authorization: `Bearer ${bobApiKey}` }
});
expect(bobResponse.status).toBe(404);

// Bob should see his own job
const bobOwnResponse = await fetch(`${BASE_URL}/jobs/${bobJobId}`, {
  headers: { Authorization: `Bearer ${bobApiKey}` }
});
expect(bobOwnResponse.status).toBe(200);
```

**Best Practices:**
- Always return 404 (not 403) for unauthorized access to prevent information leakage
- Test both positive (user can access own data) and negative (user cannot access other's data) cases
- Clean up test jobs in `afterEach` hooks to prevent test pollution
- Use `createTestJob()` helper to simplify multi-user test setup

**How RLS Works:**
- `index_jobs` table has SELECT policies that filter based on `repository_id`
- Jobs are visible only if the repository belongs to the user (user_id match) or their organization
- `getJobStatus()` explicitly checks repository ownership to mimic RLS behavior
- Service role client bypasses RLS, so manual filtering is required

### Test Environment Variables

Tests automatically load environment variables from `.env.test` via a preload script (`app/tests/setup.ts`). This script:

1. Runs before all tests (via `bun test --preload ./tests/setup.ts`)
2. Parses `.env.test` and loads variables into `process.env`
3. Falls back to hardcoded defaults if `.env.test` doesn't exist

**Automatic Loading (Recommended):**
```bash
# Just run tests - .env.test is loaded automatically
bun test
```

**Manual Loading (Alternative):**
```bash
# Export variables manually if needed
export $(grep -v '^#' .env.test | xargs)
bun test
```

The `.env.test` file typically contains:
```bash
SUPABASE_URL=http://localhost:<dynamic-port>
SUPABASE_SERVICE_KEY=<generated-jwt>
SUPABASE_ANON_KEY=<generated-jwt>
DATABASE_URL=postgresql://postgres:postgres@localhost:<dynamic-port>/postgres
```

### Example Test

```typescript
import { describe, expect, test, beforeAll, afterAll } from "bun:test";
import { createAuthHeader } from "../helpers/db";

const TEST_PORT = 3100;
let server: ReturnType<typeof Bun.serve>;

beforeAll(async () => {
  // Set test environment
  process.env.SUPABASE_URL = "http://localhost:5434";
  process.env.SUPABASE_SERVICE_KEY = "test-service-key-local";
  process.env.SUPABASE_ANON_KEY = "test-anon-key-local";
  process.env.DATABASE_URL = "postgresql://postgres:postgres@localhost:5434/postgres";

  // Start test server with real database
  const { createRouter } = await import("@api/routes");
  const { getServiceClient } = await import("@db/client");

  const supabase = getServiceClient();
  const router = createRouter(supabase);

  server = Bun.serve({
    port: TEST_PORT,
    fetch: router.handle,
  });
});

afterAll(() => {
  server.stop();
});

describe("My Feature", () => {
  test("does something", async () => {
    const response = await fetch(`http://localhost:${TEST_PORT}/endpoint`, {
      headers: {
        "Authorization": createAuthHeader("free"),
      },
    });

    expect(response.status).toBe(200);
  });
});
```

## MCP Testing

KotaDB provides comprehensive MCP (Model Context Protocol) integration testing with real Supabase database connections.

### MCP Test Files

The MCP test suite includes 9 test files covering all aspects of the MCP integration:

- `app/tests/mcp/lifecycle.test.ts` - Protocol handshake and tool discovery
- `app/tests/mcp/errors.test.ts` - JSON-RPC error handling
- `app/tests/mcp/authentication.test.ts` - Auth and rate limiting
- `app/tests/mcp/tool-validation.test.ts` - Parameter validation for all tools
- `app/tests/mcp/tools.test.ts` - Tool execution tests
- `app/tests/mcp/integration.test.ts` - End-to-end workflows
- `app/tests/mcp/concurrent.test.ts` - Concurrency and isolation
- `app/tests/mcp/handshake.test.ts` - Basic handshake tests
- `app/tests/mcp/headers.test.ts` - Header validation

### MCP Test Helpers

Import MCP-specific test helpers from `tests/helpers/mcp.ts`:

```typescript
import {
  sendMcpRequest,
  extractToolResult,
  createMcpHeaders,
  assertToolResult,
  assertJsonRpcError
} from "../helpers/mcp";

// Send MCP request with authentication
const response = await sendMcpRequest(
  baseUrl,
  "tools/call",
  {
    name: "search_code",
    arguments: { term: "Router" }
  },
  "free"  // tier: free, solo, or team
);

// Extract tool result from SDK content blocks
const result = extractToolResult(response.data);
console.log(result.results);

// Assert tool result has expected fields
assertToolResult(response.data, {
  results: "object",
  total: "number"
});

// Assert JSON-RPC error with code and message pattern
assertJsonRpcError(response.data, -32603, /missing.*term/i);
```

### SDK Content Block Response Format

The MCP SDK wraps tool results in content blocks. Tests must extract results using the `extractToolResult()` helper:

```typescript
// Raw SDK response
{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "content": [
      {
        "type": "text",
        "text": "{\"results\": [...], \"total\": 10}"
      }
    ]
  }
}

// Extracted tool result
const toolResult = extractToolResult(response.data);
// => { results: [...], total: 10 }
```

### SDK Error Code Mapping

The MCP SDK uses specific JSON-RPC error codes:

- `-32700` (Parse Error): Invalid JSON or malformed JSON-RPC structure (returns HTTP 400)
- `-32601` (Method Not Found): Unknown JSON-RPC method (returns HTTP 200)
- `-32603` (Internal Error): Tool execution errors, validation failures, type errors (returns HTTP 200)

**Important:** The SDK uses `-32603` for all tool-level errors, NOT `-32602` (Invalid Params).

### Running MCP Tests

```bash
# Run all MCP tests
bun test tests/mcp/

# Run specific MCP test file
bun test tests/mcp/lifecycle.test.ts

# Run MCP tests with coverage
bun test --coverage tests/mcp/
```

### Example MCP Test

```typescript
import { afterAll, beforeAll, describe, expect, test } from "bun:test";
import type { Server } from "node:http";
import { sendMcpRequest, extractToolResult } from "../helpers/mcp";
import { startTestServer, stopTestServer } from "../helpers/server";

let server: Server;
let baseUrl: string;

beforeAll(async () => {
  const testServer = await startTestServer();
  server = testServer.server;
  baseUrl = testServer.url;
});

afterAll(async () => {
  await stopTestServer(server);
});

describe("MCP Tools", () => {
  test("search_code finds matching files", async () => {
    const response = await sendMcpRequest(
      baseUrl,
      "tools/call",
      {
        name: "search_code",
        arguments: { term: "Router", limit: 10 }
      },
      "free"
    );

    expect(response.status).toBe(200);
    const result = extractToolResult(response.data);
    expect(result.results).toBeArray();
  });
});
```

### MCP Test Fixtures

Test fixtures for MCP integration testing are located in `app/tests/fixtures/mcp/`:

- `sample-repository/` - Minimal test repository for indexing tests
  - `index.ts` - Sample TypeScript file with classes and functions
  - `utils.ts` - Sample utility functions
  - `package.json` - Repository metadata
- `expected-responses/` - JSON files with expected tool results for comparison

Use fixtures in tests:

```typescript
import path from "node:path";

const fixturePath = path.join(
  process.cwd(),
  "tests/fixtures/mcp/sample-repository"
);

const response = await sendMcpRequest(
  baseUrl,
  "tools/call",
  {
    name: "index_repository",
    arguments: {
      repository: "test/fixture-repo",
      localPath: fixturePath
    }
  },
  "free"
);
```

### Claude Code Integration Testing

For manual testing with Claude Code CLI, see [docs/guides/mcp-claude-code-integration.md](../guides/mcp-claude-code-integration.md).

## Code Coverage

KotaDB tracks code coverage for both the application (TypeScript) and automation (Python) layers to ensure comprehensive test coverage.

### Running Coverage Locally

**Application Coverage (Bun):**
```bash
cd app
bun test --coverage
```

Bun generates coverage reports in multiple formats:
- Terminal output: Summary shown after test run
- HTML report: `app/coverage/index.html` (open in browser)
- LCOV format: `app/coverage.lcov` (for CI integration)

**Automation Coverage (pytest-cov):**
```bash
cd automation
uv run pytest adws/adw_tests/ --cov=adws --cov-report=html --cov-report=term
```

Coverage reports are generated in:
- Terminal output: Summary with line-by-line coverage
- HTML report: `automation/htmlcov/index.html` (open in browser)
- JSON report: `automation/coverage.json` (for programmatic access)

### Coverage Configuration

**Application Coverage:**
Bun uses built-in coverage support with no additional configuration needed. Coverage includes:
- All source files in `app/src/`
- Excludes test files and node_modules

**Automation Coverage:**
Configuration is defined in `automation/pyproject.toml`:
```toml
[tool.coverage.run]
source = ["adws"]
omit = [
    "*/tests/*",
    "*/adw_tests/*",
    "*/__pycache__/*",
    "*/site-packages/*",
    "*/.venv/*"
]
```

### CI Coverage Reporting

Both CI workflows automatically generate and upload coverage reports:

**Application CI** (`.github/workflows/app-ci.yml`):
- Runs tests with coverage enabled
- Uploads coverage report as GitHub artifact
- Displays coverage summary in GitHub Step Summary

**Automation CI** (`.github/workflows/automation-ci.yml`):
- Runs pytest with coverage tracking
- Uploads coverage report as GitHub artifact
- Shows coverage percentage in GitHub Step Summary

### Coverage Artifacts

After CI runs complete, coverage reports are available as downloadable artifacts:
- `app-coverage-report`: Application coverage (HTML + LCOV)
- `automation-coverage-report`: Automation coverage (HTML + JSON + LCOV)

Artifacts are retained for 30 days.

### Coverage Baselines

Coverage baselines are tracked to monitor testing quality over time:

**Application Coverage Baseline:**
- Total: TBD (to be measured after first CI run)
- Target: 80% for critical paths (auth, rate limiting, MCP)

**Automation Coverage Baseline:**
- Total: TBD (to be measured after first CI run)
- Target: 80% for ADW workflow logic

### Viewing Coverage Reports

**Locally:**
```bash
# App coverage
open app/coverage/index.html

# Automation coverage
open automation/htmlcov/index.html
```

**CI Artifacts:**
1. Go to GitHub Actions run
2. Scroll to "Artifacts" section at bottom
3. Download `app-coverage-report` or `automation-coverage-report`
4. Extract and open `index.html` in browser

## Available Package Scripts

KotaDB provides convenient npm/bun scripts for common test workflows:

| Script | Command | Description |
|--------|---------|-------------|
| `test:setup` | `./scripts/setup-test-db.sh` | First-time setup: start Supabase, generate .env.test, seed data |
| `test:teardown` | `supabase stop` | Stop all Supabase Local services |
| `test:reset` | `./scripts/reset-test-db.sh` | Reset database to clean state and re-seed |
| `test:env` | `./scripts/generate-env-test.sh` | Regenerate .env.test from Supabase status |
| `test:status` | `supabase status` | Show status of all Supabase services |
## Supabase Local Port Architecture

When using Supabase Local (via Docker), multiple services run on different ports:

| Port  | Service            | Purpose                                      | Usage                              |
|-------|--------------------|--------------------------------------------- |------------------------------------|
| 5434  | PostgreSQL         | Direct database access                       | Migrations, seed scripts, psql CLI |
| 54322 | PostgREST          | REST API (no routing layer)                  | Direct HTTP database access        |
| 54325 | GoTrue             | Authentication service                       | User auth operations               |
| 54326 | Kong Gateway       | API gateway with /rest/v1/ routing           | **Supabase JS client (tests use this)** |

### Critical Configuration for Tests

**The Supabase JS client requires the Kong gateway port (54326), not PostgREST (54322).**

Kong provides the `/rest/v1/` routing layer that the Supabase JS client expects. Direct PostgREST access doesn't include this routing, causing 404 errors when the client tries to access `/rest/v1/table_name`.

**Test Configuration (`.env.test`):**
```bash
SUPABASE_URL=http://localhost:54326  # Kong gateway, NOT 54322
SUPABASE_SERVICE_KEY=test-service-key-local
SUPABASE_ANON_KEY=test-anon-key-local
DATABASE_URL=postgresql://postgres:postgres@localhost:5434/postgres
```

All test files set these environment variables at module-level (before imports) to ensure the Supabase client initializes with correct configuration.

## Troubleshooting

### Tests Fail with 404 or "relation not found"

**Symptom:** Tests fail with 404 errors or PostgREST returns empty results even though data exists.

**Cause:** SUPABASE_URL is pointing to PostgREST (port 54322) instead of Kong gateway (port 54326).

**Solution:**
1. Check `.env.test` - should use `http://localhost:54326` (Kong gateway)
2. Verify test files set `process.env.SUPABASE_URL = "http://localhost:54326"` at module-level
3. Ensure imports happen AFTER environment variables are set

### Tests Fail with "null API key validation" or "401 Unauthorized"

**Symptom:** Auth tests fail with null validation results or unauthorized errors.

**Cause:** Supabase client initialized before test environment variables were set.

**Solution:**
1. Move env var setup to top of test file (before any imports)
2. Use dynamic imports in `beforeAll` after env vars are configured:
   ```typescript
   process.env.SUPABASE_URL = "http://localhost:54326";
   // ... other env vars

   beforeAll(async () => {
     const { getServiceClient } = await import("@db/client");
     // ... rest of setup
   });
   ```

### Cache Timing Tests Are Flaky

**Symptom:** Tests that verify cache performance fail intermittently with timing assertions.

**Cause:** Real database operations have timing variance (network latency, database load).

**Solution:** Use tolerance-based assertions instead of strict comparisons:
```typescript
// ❌ Flaky
expect(secondDuration).toBeLessThan(firstDuration);

// ✅ Stable
expect(secondDuration).toBeLessThanOrEqual(firstDuration + 2);
```

### Port Already in Use

**Example workflow:**

```bash
# First time setup
bun run test:setup

# Run tests
bun test

# Need fresh data? Reset
bun run test:reset && bun test

# Done for the day
bun run test:teardown
```

## Troubleshooting

### Supabase CLI Not Installed

**Error:** `supabase: command not found`

**Solution:**
```bash
brew install supabase/tap/supabase  # macOS
# Or see: https://supabase.com/docs/guides/cli
```

### jq Not Installed

**Error:** `jq: command not found`

**Solution:**
```bash
brew install jq  # macOS
# Or: apt-get install jq (Linux)
```

### Docker Not Running

**Error:** `Cannot connect to the Docker daemon`

**Solution:**
- Start Docker Desktop (macOS/Windows)
- Or: `sudo systemctl start docker` (Linux)

### Port Already in Use

**Error:** `Port 5434 is already allocated`

**Solution:**
```bash
# Check what's using the port
lsof -ti:5434

# Stop conflicting Supabase instance
supabase stop

# Or kill the process
kill $(lsof -ti:5434)
```

### Tests Fail with "Connection Refused"

**Error:** `ECONNREFUSED localhost:5434`

**Solution:**
```bash
# Check if Supabase is running
bun run test:status

# If not running, start it
bun run test:setup
```

### .env.test Generation Failed

**Error:** `Failed to extract API keys from Supabase status`

**Solution:**
```bash
# Check Supabase status manually
supabase status --output json

# If services aren't running, restart
supabase stop && bun run test:setup
```

### Schema Mismatch Errors

**Error:** `relation "api_keys" does not exist`

**Solution:**
```bash
# Reset Supabase Local completely
supabase db reset

# Or stop and restart fresh
supabase stop
bun run test:setup
```

### Stale .env.test After Restart

If `.env.test` credentials don't match running services:

```bash
# Regenerate .env.test from current Supabase status
bun run test:env

# Verify credentials
cat .env.test
```

## CI/CD Integration

KotaDB's CI environment uses **Supabase Local** via GitHub Actions to achieve **exact parity** with local testing. This follows the antimocking philosophy by ensuring CI tests run against the same full-stack Supabase environment as local development.

### CI Architecture

The GitHub Actions workflow (`.github/workflows/ci.yml`) uses the official `supabase/setup-cli@v1` action to install Supabase CLI, then runs `.github/scripts/setup-supabase-ci.sh` to:

1. **Initialize Supabase config** (if not present)
2. **Start Supabase Local services** via `supabase start` (PostgreSQL + PostgREST + Kong + Auth)
3. **Wait for readiness** with health checks and retries
4. **Auto-generate `.env.test`** from `supabase status --output json`
5. **Seed test data** from `supabase/seed.sql`

### Why Supabase Local in CI?

**Before (broken):** CI used plain PostgreSQL service without PostgREST or Supabase stack, causing:
- ❌ 401 Unauthorized errors (API key validation requires PostgREST RPC)
- ❌ Tests pass locally but fail in CI (false confidence)
- ❌ Environment drift violates antimocking principles

**After (fixed):** CI uses Supabase Local for:
- ✅ Exact parity with local testing (same services, ports, credentials)
- ✅ Real authentication flow (PostgREST RPC endpoints work)
- ✅ Consistent test results (133/133 tests pass locally and in CI)
- ✅ Antimocking compliance (no mocks/stubs to work around missing services)

### CI Workflow Steps

```yaml
- name: Setup Supabase CLI
  uses: supabase/setup-cli@v1
  with:
    version: latest

- name: Setup Supabase Local and generate test credentials
  run: .github/scripts/setup-supabase-ci.sh

- name: Validate migration sync
  run: bun run test:validate-migrations

- name: Test
  run: |
    export $(grep -v '^#' .env.test | xargs)
    bun test

- name: Teardown Supabase Local
  if: always()
  run: supabase stop
```

### CI Execution Time

Target: **Under 2 minutes** total (acceptable trade-off for testing parity)

Breakdown:
- Supabase startup: ~30-60 seconds (first run may be slower, cached thereafter)
- Test execution: ~13.5 seconds (133 tests)
- Migration validation, typecheck, lint: ~10-20 seconds

### Troubleshooting CI Failures

**401 Unauthorized errors in CI:**
- Check `.github/scripts/setup-supabase-ci.sh` successfully generated `.env.test`
- Verify `supabase start` completed without errors
- Ensure test step sources `.env.test` before running `bun test`

**Timeout during Supabase startup:**
- GitHub Actions has generous Docker limits, but Supabase startup may occasionally be slow
- Script includes 30-retry health check loop (60 seconds total timeout)
- Check "Setup Supabase Local" step logs for startup errors

**Migration sync failures:**
- Ensure `src/db/migrations/` and `supabase/migrations/` are synchronized
- Run `bun run test:validate-migrations` locally before pushing
- CI runs this validation automatically to catch drift
- **Migration Naming Convention**: All migrations must use timestamped format `YYYYMMDDHHMMSS_description.sql` (e.g., `20241024143000_add_feature.sql`)
  - Prevents merge conflicts in concurrent development
  - Ensures deterministic ordering across file systems
  - Aligns with Supabase CLI expectations

## Antimocking Migration Complete

The KotaDB test suite now uses real PostgreSQL database connections instead of mocks.

**✅ Completed:**
- PostgreSQL test database container setup via Docker Compose
- Schema migrations for test environment (auth schema + main schema)
- Test data seeding scripts with deterministic test users, API keys, and repositories
- Real database test helper functions (`tests/helpers/db.ts`)
- All test files refactored to use real database:
  - MCP tests (`tests/mcp/*.test.ts`)
  - API tests (`tests/api/authenticated-routes.test.ts`)
  - Auth tests (`tests/auth/middleware.test.ts`, `tests/auth/validator.test.ts`)
- Mock helper files deleted (`tests/helpers/supabase-mock.ts`, `tests/helpers/auth-mock.ts`)
- CI/CD integration with PostgreSQL service container
- Setup and reset scripts for local development

**Benefits:**
- Tests exercise real database behavior (connections, timeouts, transactions)
- No mock maintenance burden
- True confidence in authentication and database flows
- Production parity testing

## Manual Database Inspection

To inspect the test database manually:

```bash
# Connect via psql
PGPASSWORD=postgres psql -h localhost -p 5434 -U postgres -d postgres

# Useful queries
SELECT * FROM api_keys;
SELECT * FROM indexed_files;
SELECT * FROM repositories;

# Check schema
\dt  -- List tables
\d api_keys  -- Describe api_keys table
```

## References

- [Anti-Mock Philosophy](../.claude/commands/anti-mock.md)
- [Supabase Setup Guide](./supabase-setup.md)
- [Database Schema](./schema.md)
- [Migration Guide (SQLite → Postgres)](./migration-sqlite-to-supabase.md)
